åŸºäºä¸‹é¢çš„ä¿¡æ¯ï¼Œç»™å‡ºè‹±æ–‡æŠ€æœ¯åšå®¢æ–‡ç« ï¼ˆé¢å‘æ¬§ç¾ç”¨æˆ·ï¼ŒåŸºäº Google Adsenseèµšé’±ï¼‰ï¼š
æ–‡ç« ä¸ºä¸»ï¼Œä»£ç ä¸ºè¾…ã€‚
è¦æœ‰å›¾è¡¨å’Œè¡¨æ ¼ã€‚

Reference Title: Deploying Spring AI Apps to Kubernetes: Complete Guide
Reference Keywords: spring ai kubernetes
Target Word Count: 6000-7000

markdown æ‘˜è¦ä¿¡æ¯çš„æ ¼å¼å¦‚ä¸‹ï¼š
---
title: "xxxx"
date: "2025-xx-xx"
author: "SpringDevPro Team"
tags: [xxx, xxx]
categories: [Spring AI]
description: "xxxx"
keywords: "xxx, xxx"
featured_image: "xxxx"
reading_time: "xx min read"
difficulty: "xx"
---

---
title: "Deploying Spring AI Applications to Kubernetes: The Complete Production Guide"
date: "2025-11-20"
author: "SpringDevPro Team"
tags: [spring-ai, kubernetes, deployment, devops, cloud-native, docker]
categories: [Spring AI, DevOps, Kubernetes]
description: "Master Kubernetes deployment for Spring AI applications. Learn containerization, orchestration, auto-scaling, secret management, monitoring, and production best practices. Includes real-world examples, troubleshooting guides, and cost optimization strategies."
keywords: "spring ai kubernetes, kubernetes deployment, spring ai docker, kubernetes ai apps, spring boot kubernetes, ai microservices deployment"
featured_image: "images/spring-ai-kubernetes-deployment.png"
reading_time: "35 min read"
difficulty: "Advanced"
---

# Deploying Spring AI Applications to Kubernetes: The Complete Production Guide

## The Midnight Deployment That Changed Everything

It was 11:47 PM on a Friday when Sarah received the alert: **"AI service down in production. All customer queries failing."**

Her team had deployed their Spring AI chatbot to a single VM three months ago. It worked perfectlyâ€”until it didn't.

**What went wrong:**
- ğŸ’¥ VM crashed, no redundancy
- â±ï¸ Manual restart took 23 minutes
- ğŸ’° Lost $15,000 in sales during downtime
- ğŸ˜¤ Angry customers flooded social media
- ğŸ“‰ Stock price dropped 2.3%

**The post-mortem revealed:**
- âŒ No automatic failover
- âŒ No health monitoring
- âŒ No auto-scaling (traffic spike killed the server)
- âŒ No rolling updates (deployments meant downtime)
- âŒ No resource limits (one bad request consumed all memory)

**Sarah's team made a decision:** Move to Kubernetes.

**Results after Kubernetes migration:**
- âœ… **99.99% uptime** (3 months without incident)
- âœ… **Zero-downtime deployments** (weekly updates)
- âœ… **Auto-scaling** from 3 to 50 pods during Black Friday
- âœ… **Cost reduced 40%** (better resource utilization)
- âœ… **Sarah sleeps at night** (no more midnight emergencies)

**This guide shows you how to achieve the same results.**

## Why Kubernetes for Spring AI Applications?

### The Traditional Deployment Problem

```
Traditional VM Deployment:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Single VM                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Spring AI App                â”‚  â”‚
â”‚  â”‚  - 4GB RAM allocated          â”‚  â”‚
â”‚  â”‚  - Uses 400MB normally        â”‚  â”‚  â† Waste 3.6GB
â”‚  â”‚  - Spikes to 6GB under load   â”‚  â”‚  â† Crashes
â”‚  â”‚  - No automatic recovery      â”‚  â”‚
â”‚  â”‚  - Manual scaling required    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problems:
1. Resource waste (90% idle resources)
2. No fault tolerance (single point of failure)
3. Slow scaling (manual VM provisioning)
4. Downtime during updates (stop â†’ update â†’ start)
5. No environment parity (dev â‰  prod)
```

### The Kubernetes Advantage

```
Kubernetes Deployment:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Pod 1   â”‚  â”‚  Pod 2   â”‚  â”‚  Pod 3   â”‚  â”‚  Pod N   â”‚  â”‚
â”‚  â”‚  400MB   â”‚  â”‚  400MB   â”‚  â”‚  400MB   â”‚  â”‚  auto    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚             â”‚             â”‚             â”‚         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                Load Balancer                               â”‚
â”‚                                                            â”‚
â”‚  Auto-scaling: 3 â†’ 50 pods based on load                  â”‚
â”‚  Self-healing: Auto-restart failed pods                   â”‚
â”‚  Rolling updates: Zero downtime deployments                â”‚
â”‚  Resource efficiency: 85% utilization                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
1. High availability (multi-pod redundancy)
2. Auto-scaling (CPU/memory/custom metrics)
3. Self-healing (automatic restart on failure)
4. Zero-downtime updates (rolling deployments)
5. Resource efficiency (85%+ utilization)
6. Environment consistency (same everywhere)
```

### Cost Comparison: VM vs Kubernetes

| Aspect | Traditional VMs | Kubernetes | Savings |
|--------|----------------|------------|---------|
| **Base Infrastructure** | 5 VMs Ã— $200/mo = $1,000 | 1 cluster @ $600/mo | 40% |
| **Scaling** | Manual, pre-provision | Auto-scale on demand | 60% |
| **Utilization** | 15-30% | 70-85% | 3-5x better |
| **Operational Cost** | 2 FTE DevOps | 0.5 FTE (automation) | 75% |
| **Downtime Cost** | $5K/hour | Near zero | 100% |
| **Total Monthly** | ~$1,800 | ~$900 | **50% savings** |

## Architecture Overview

### Spring AI on Kubernetes: Complete Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Users/Clients                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Ingress Controller                         â”‚
â”‚              (nginx/traefik - HTTPS termination)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Kubernetes Service                          â”‚
â”‚                  (Load Balancer)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Pod 1   â”‚      â”‚ Pod 2   â”‚      â”‚ Pod 3   â”‚
    â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚      â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚      â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚
    â”‚â”‚Spring â”‚â”‚      â”‚â”‚Spring â”‚â”‚      â”‚â”‚Spring â”‚â”‚
    â”‚â”‚  AI   â”‚â”‚      â”‚â”‚  AI   â”‚â”‚      â”‚â”‚  AI   â”‚â”‚
    â”‚â”‚  App  â”‚â”‚      â”‚â”‚  App  â”‚â”‚      â”‚â”‚  App  â”‚â”‚
    â”‚â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚      â”‚â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚      â”‚â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                â”‚                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                                â”‚
          â–¼                                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Redis   â”‚                    â”‚PostgreSQLâ”‚
    â”‚  Cache   â”‚                    â”‚   DB     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Vector  â”‚
    â”‚   Store  â”‚
    â”‚(Pinecone)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Step 1: Containerizing Your Spring AI Application

### 1.1 Multi-Stage Dockerfile

```dockerfile
# Dockerfile - Optimized for Spring AI
FROM eclipse-temurin:21-jdk-alpine AS builder

WORKDIR /app

# Copy Maven wrapper and pom.xml
COPY .mvn/ .mvn/
COPY mvnw pom.xml ./

# Download dependencies (cached layer)
RUN ./mvnw dependency:go-offline

# Copy source code
COPY src ./src

# Build application
RUN ./mvnw clean package -DskipTests

# Extract JAR layers
RUN mkdir -p target/extracted && \
    java -Djarmode=layertools -jar target/*.jar extract --destination target/extracted

# Runtime stage
FROM eclipse-temurin:21-jre-alpine

# Add non-root user
RUN addgroup -S spring && adduser -S spring -G spring

# Install curl for health checks
RUN apk add --no-cache curl

WORKDIR /app

# Copy layers from builder
COPY --from=builder /app/target/extracted/dependencies/ ./
COPY --from=builder /app/target/extracted/spring-boot-loader/ ./
COPY --from=builder /app/target/extracted/snapshot-dependencies/ ./
COPY --from=builder /app/target/extracted/application/ ./

# Switch to non-root user
USER spring:spring

# Expose port
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8080/actuator/health || exit 1

# JVM options for containers
ENV JAVA_OPTS="-XX:+UseContainerSupport \
               -XX:MaxRAMPercentage=75.0 \
               -XX:+UseG1GC \
               -XX:+UseStringDeduplication \
               -Djava.security.egd=file:/dev/./urandom"

# Run application
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS org.springframework.boot.loader.launch.JarLauncher"]
```

### 1.2 Docker Compose for Local Testing

```yaml
# docker-compose.yml
version: '3.8'

services:
  spring-ai-app:
    build: .
    ports:
      - "8080:8080"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - SPRING_AI_OPENAI_API_KEY=${OPENAI_API_KEY}
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/springai
      - SPRING_DATA_REDIS_HOST=redis
    depends_on:
      - postgres
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_DB=springai
      - POSTGRES_USER=springai
      - POSTGRES_PASSWORD=changeme
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes

volumes:
  postgres-data:
  redis-data:
```

### 1.3 Build and Test

```bash
# Build Docker image
docker build -t spring-ai-app:1.0.0 .

# Run locally with Docker Compose
docker-compose up -d

# Test the application
curl http://localhost:8080/actuator/health

# Check logs
docker-compose logs -f spring-ai-app

# Stop
docker-compose down
```

## Step 2: Kubernetes Configuration

### 2.1 Namespace

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: spring-ai
  labels:
    name: spring-ai
    environment: production
```

### 2.2 ConfigMap

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spring-ai-config
  namespace: spring-ai
data:
  application.yml: |
    spring:
      application:
        name: spring-ai-app
      
      datasource:
        url: jdbc:postgresql://postgres-service:5432/springai
        username: springai
        hikari:
          maximum-pool-size: 10
          minimum-idle: 5
      
      data:
        redis:
          host: redis-service
          port: 6379
      
      ai:
        openai:
          chat:
            options:
              model: gpt-4o-mini
              max-tokens: 2000
      
    server:
      port: 8080
      shutdown: graceful
      compression:
        enabled: true
    
    management:
      endpoints:
        web:
          exposure:
            include: health,info,metrics,prometheus
      endpoint:
        health:
          probes:
            enabled: true
          show-details: when-authorized
      metrics:
        export:
          prometheus:
            enabled: true
    
    logging:
      level:
        root: INFO
        org.springframework.ai: DEBUG
```

### 2.3 Secrets

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: spring-ai-secrets
  namespace: spring-ai
type: Opaque
stringData:
  openai-api-key: "your-openai-api-key-here"
  postgres-password: "your-postgres-password"
  redis-password: "your-redis-password"
```

**Important:** Don't commit secrets to Git. Use sealed-secrets or external secret managers:

```bash
# Using Sealed Secrets
kubeseal --format=yaml < secrets.yaml > sealed-secrets.yaml

# Using AWS Secrets Manager
kubectl create secret generic spring-ai-secrets \
  --from-literal=openai-api-key=$(aws secretsmanager get-secret-value \
    --secret-id openai-api-key --query SecretString --output text)
```

### 2.4 Deployment

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-ai-deployment
  namespace: spring-ai
  labels:
    app: spring-ai
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: spring-ai
  template:
    metadata:
      labels:
        app: spring-ai
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/actuator/prometheus"
    spec:
      serviceAccountName: spring-ai-sa
      
      # Pod Anti-Affinity (spread across nodes)
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - spring-ai
              topologyKey: kubernetes.io/hostname
      
      # Init container for database migration
      initContainers:
      - name: wait-for-db
        image: busybox:1.36
        command: ['sh', '-c', 'until nc -z postgres-service 5432; do echo waiting for postgres; sleep 2; done;']
      
      containers:
      - name: spring-ai
        image: your-registry/spring-ai:1.0.0
        imagePullPolicy: Always
        
        ports:
        - containerPort: 8080
          name: http
          protocol: TCP
        
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "kubernetes"
        - name: SPRING_CONFIG_LOCATION
          value: "file:/config/application.yml"
        - name: SPRING_AI_OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: spring-ai-secrets
              key: openai-api-key
        - name: SPRING_DATASOURCE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: spring-ai-secrets
              key: postgres-password
        - name: JAVA_OPTS
          value: "-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0"
        
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        
        # Liveness probe
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        # Readiness probe
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        
        # Startup probe (for slow-starting apps)
        startupProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 30
        
        # Mount config
        volumeMounts:
        - name: config
          mountPath: /config
          readOnly: true
      
      volumes:
      - name: config
        configMap:
          name: spring-ai-config
      
      # Graceful shutdown
      terminationGracePeriodSeconds: 30
```

### 2.5 Service

```yaml
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: spring-ai-service
  namespace: spring-ai
  labels:
    app: spring-ai
spec:
  type: ClusterIP
  selector:
    app: spring-ai
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
```

### 2.6 Horizontal Pod Autoscaler (HPA)

```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: spring-ai-hpa
  namespace: spring-ai
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: spring-ai-deployment
  minReplicas: 3
  maxReplicas: 20
  metrics:
  # CPU-based scaling
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  
  # Memory-based scaling
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  
  # Custom metric: AI requests per second
  - type: Pods
    pods:
      metric:
        name: ai_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
  
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Min
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 4
        periodSeconds: 30
      selectPolicy: Max
```

### 2.7 Ingress

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: spring-ai-ingress
  namespace: spring-ai
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/limit-rps: "10"
spec:
  tls:
  - hosts:
    - api.yourcompany.com
    secretName: spring-ai-tls
  rules:
  - host: api.yourcompany.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: spring-ai-service
            port:
              number: 80
```

## Step 3: Supporting Services

### 3.1 PostgreSQL StatefulSet

```yaml
# k8s/postgres.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: spring-ai
spec:
  serviceName: postgres-service
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:16-alpine
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          value: springai
        - name: POSTGRES_USER
          value: springai
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: spring-ai-secrets
              key: postgres-password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
  namespace: spring-ai
spec:
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432
  clusterIP: None
```

### 3.2 Redis Deployment

```yaml
# k8s/redis.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: spring-ai
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        volumeMounts:
        - name: redis-data
          mountPath: /data
      volumes:
      - name: redis-data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
  namespace: spring-ai
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
```

## Step 4: Deployment Process

### 4.1 Deploy to Kubernetes

```bash
# Create namespace
kubectl apply -f k8s/namespace.yaml

# Apply secrets (use sealed-secrets in production)
kubectl apply -f k8s/secrets.yaml

# Apply ConfigMap
kubectl apply -f k8s/configmap.yaml

# Deploy supporting services
kubectl apply -f k8s/postgres.yaml
kubectl apply -f k8s/redis.yaml

# Wait for databases to be ready
kubectl wait --for=condition=ready pod -l app=postgres -n spring-ai --timeout=300s
kubectl wait --for=condition=ready pod -l app=redis -n spring-ai --timeout=300s

# Deploy application
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/hpa.yaml
kubectl apply -f k8s/ingress.yaml

# Watch deployment progress
kubectl rollout status deployment/spring-ai-deployment -n spring-ai

# Check pods
kubectl get pods -n spring-ai

# Check logs
kubectl logs -f deployment/spring-ai-deployment -n spring-ai
```

### 4.2 Verify Deployment

```bash
# Check all resources
kubectl get all -n spring-ai

# Test service internally
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \
  curl http://spring-ai-service.spring-ai.svc.cluster.local/actuator/health

# Check HPA status
kubectl get hpa -n spring-ai

# View events
kubectl get events -n spring-ai --sort-by='.lastTimestamp'
```

## Step 5: Monitoring & Observability

### 5.1 Prometheus ServiceMonitor

```yaml
# k8s/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: spring-ai-metrics
  namespace: spring-ai
  labels:
    app: spring-ai
spec:
  selector:
    matchLabels:
      app: spring-ai
  endpoints:
  - port: http
    path: /actuator/prometheus
    interval: 30s
```

### 5.2 Grafana Dashboard

```yaml
# k8s/grafana-dashboard.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spring-ai-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  spring-ai-dashboard.json: |
    {
      "dashboard": {
        "title": "Spring AI Application",
        "panels": [
          {
            "title": "Request Rate",
            "targets": [
              {
                "expr": "rate(ai_requests_total[5m])"
              }
            ]
          },
          {
            "title": "Error Rate",
            "targets": [
              {
                "expr": "rate(ai_requests_failed[5m]) / rate(ai_requests_total[5m])"
              }
            ]
          },
          {
            "title": "Response Time (p95)",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(ai_request_duration_seconds_bucket[5m]))"
              }
            ]
          },
          {
            "title": "Active Pods",
            "targets": [
              {
                "expr": "count(kube_pod_info{namespace=\"spring-ai\",pod=~\"spring-ai-.*\"})"
              }
            ]
          }
        ]
      }
    }
```

### 5.3 Alerting Rules

```yaml
# k8s/prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: spring-ai-alerts
  namespace: spring-ai
spec:
  groups:
  - name: spring-ai
    interval: 30s
    rules:
    # High error rate
    - alert: HighErrorRate
      expr: |
        rate(ai_requests_failed[5m]) / rate(ai_requests_total[5m]) > 0.05
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High error rate in Spring AI"
        description: "Error rate is {{ $value | humanizePercentage }}"
    
    # High latency
    - alert: HighLatency
      expr: |
        histogram_quantile(0.95, rate(ai_request_duration_seconds_bucket[5m])) > 5
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "High latency in Spring AI"
        description: "95th percentile latency is {{ $value }}s"
    
    # Pod crash loop
    - alert: PodCrashLooping
      expr: |
        rate(kube_pod_container_status_restarts_total{namespace="spring-ai"}[15m]) > 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Pod is crash looping"
        description: "Pod {{ $labels.pod }} is restarting"
    
    # Low pod count
    - alert: LowPodCount
      expr: |
        count(kube_pod_info{namespace="spring-ai",pod=~"spring-ai-.*"}) < 2
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Low pod count"
        description: "Only {{ $value }} pods running"
```

## Step 6: CI/CD Pipeline

### 6.1 GitHub Actions

```yaml
# .github/workflows/deploy.yaml
name: Deploy to Kubernetes

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: maven
      
      - name: Run tests
        run: ./mvnw test
      
      - name: Run integration tests
        run: ./mvnw verify -Pintegration-tests

  build:
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
      
      - name: Configure kubectl
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $HOME/.kube/config
      
      - name: Update image in deployment
        run: |
          kubectl set image deployment/spring-ai-deployment \
            spring-ai=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ github.sha }} \
            -n spring-ai
      
      - name: Wait for rollout
        run: |
          kubectl rollout status deployment/spring-ai-deployment -n spring-ai --timeout=5m
      
      - name: Run smoke tests
        run: |
          kubectl run smoke-test --image=curlimages/curl --rm -it --restart=Never -- \
            curl -f http://spring-ai-service.spring-ai.svc.cluster.local/actuator/health || exit 1
      
      - name: Notify on success
        if: success()
        run: echo "Deployment successful!"
      
      - name: Rollback on failure
        if: failure()
        run: |
          kubectl rollout undo deployment/spring-ai-deployment -n spring-ai
          exit 1
```

## Step 7: Troubleshooting Guide

### Common Issues & Solutions

| Issue | Symptoms | Solution |
|-------|----------|----------|
| **Pods CrashLooping** | Pods repeatedly restart | Check logs: `kubectl logs <pod>` <br> Check resources: Insufficient CPU/memory <br> Check liveness probe: Too aggressive |
| **ImagePullBackOff** | Cannot pull image | Verify image exists <br> Check registry credentials <br> Check image tag |
| **Service Unavailable** | Cannot reach service | Check service selector matches pods <br> Verify pod ports <br> Check network policies |
| **OOM Killed** | Pod killed due to memory | Increase memory limits <br> Fix memory leaks <br> Enable heap dumps |
| **Slow Startup** | Pods take >2 minutes | Adjust startup probe <br> Optimize application startup <br> Pre-warm caches |
| **DNS Resolution Failed** | Cannot resolve service names | Check CoreDNS pods <br> Verify service exists <br> Check namespace |

### Debug Commands

```bash
# Get pod details
kubectl describe pod <pod-name> -n spring-ai

# View logs
kubectl logs <pod-name> -n spring-ai --previous  # Previous container
kubectl logs <pod-name> -n spring-ai --tail=100 -f  # Follow logs

# Execute commands in pod
kubectl exec -it <pod-name> -n spring-ai -- /bin/sh

# Port forward for local debugging
kubectl port-forward deployment/spring-ai-deployment 8080:8080 -n spring-ai

# Check resource usage
kubectl top pods -n spring-ai
kubectl top nodes

# View events
kubectl get events -n spring-ai --sort-by='.lastTimestamp'

# Check HPA metrics
kubectl get hpa -n spring-ai -w

# Debugging services
kubectl run -it --rm debug --image=nicolaka/netshoot --restart=Never -- /bin/bash
# Then inside: curl http://spring-ai-service.spring-ai.svc.cluster.local/actuator/health
```

## Step 8: Production Best Practices

### 8.1 Resource Limits Best Practices

```yaml
# Recommended resource configuration
resources:
  requests:
    memory: "512Mi"   # Guaranteed memory
    cpu: "500m"       # Guaranteed CPU (0.5 cores)
  limits:
    memory: "2Gi"     # Max memory (4x request)
    cpu: "2000m"      # Max CPU (4x request)

# Why these ratios?
# - Requests: Guaranteed resources for scheduling
# - Limits: Prevent single pod from consuming all resources
# - 4x ratio: Allows bursting while preventing resource exhaustion
```

### 8.2 Pod Disruption Budget

```yaml
# k8s/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: spring-ai-pdb
  namespace: spring-ai
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: spring-ai
```

### 8.3 Network Policies

```yaml
# k8s/networkpolicy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: spring-ai-network-policy
  namespace: spring-ai
spec:
  podSelector:
    matchLabels:
      app: spring-ai
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  egress:
  # Allow DNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
  # Allow PostgreSQL
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  # Allow Redis
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  # Allow external AI APIs (OpenAI)
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 443
```

## Cost Optimization Strategies

### Resource Right-Sizing

```
Cost Analysis:

Over-provisioned (wasteful):
â”œâ”€ 10 pods Ã— 2GB each = 20GB total
â”œâ”€ Actual usage: 4GB (20% utilization)
â”œâ”€ Cost: $200/month
â””â”€ Waste: $160/month (80%)

Right-sized:
â”œâ”€ 5 pods Ã— 1GB each = 5GB total
â”œâ”€ With auto-scaling to 10 pods on demand
â”œâ”€ Average usage: 6GB (includes bursts)
â”œâ”€ Cost: $60/month
â””â”€ Savings: $140/month (70% reduction)
```

### Recommendations

| Strategy | Savings | Implementation |
|----------|---------|----------------|
| **Right-size resources** | 40-60% | Monitor actual usage, adjust limits |
| **Use spot instances** | 70% | Tolerate interruptions for non-critical pods |
| **Cluster autoscaling** | 30-50% | Scale nodes based on demand |
| **Efficient image layers** | 10-20% | Multi-stage builds, minimize layers |
| **Pod affinity** | 15-25% | Co-locate related pods on same node |

## Conclusion: Your Kubernetes Journey

### Deployment Checklist

```
â˜ Application containerized
â˜ Multi-stage Dockerfile optimized
â˜ Secrets managed securely (no hardcoding)
â˜ ConfigMaps configured
â˜ Resource limits set appropriately
â˜ Health checks implemented (liveness, readiness, startup)
â˜ HPA configured
â˜ Pod Disruption Budget set
â˜ Network policies applied
â˜ Monitoring configured (Prometheus, Grafana)
â˜ Alerts set up
â˜ CI/CD pipeline automated
â˜ Rollback strategy tested
â˜ Documentation complete
â˜ Team trained on operations

Production Readiness Score: ____ / 15
```

### Next Steps

**Week 1:** Deploy to staging
- Set up staging cluster
- Deploy and test thoroughly
- Practice rollbacks

**Week 2:** Monitoring & Observability
- Configure Prometheus
- Create Grafana dashboards
- Set up alerts

**Week 3:** Optimization
- Monitor resource usage
- Right-size pods
- Implement cost controls

**Week 4:** Production Deployment
- Deploy to production
- Monitor closely for 48 hours
- Gather metrics and iterate

### Key Takeaways

1. **Kubernetes eliminates single points of failure** - Your application becomes highly available
2. **Auto-scaling handles traffic spikes** - No more manual intervention
3. **Rolling updates enable zero-downtime** - Deploy anytime without user impact
4. **Resource efficiency saves money** - 40-70% cost reduction vs VMs
5. **Observability is critical** - You can't improve what you don't measure

**Sarah's team succeeded. So can you.**

---

**Resources:**

- [Kubernetes Official Documentation](https://kubernetes.io/docs/)
- [Spring Boot on Kubernetes](https://spring.io/guides/gs/spring-boot-kubernetes/)
- [Kubernetes Best Practices](https://kubernetes.io/docs/concepts/configuration/overview/)
- [Cost Optimization Guide](https://www.cncf.io/blog/2021/06/29/finops-for-kubernetes/)

**Ready to deploy? Let's do this. ğŸš€**