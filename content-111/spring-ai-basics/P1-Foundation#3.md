---
title: "Complete Guide to Spring AI Architecture and Core Concepts"
date: "2025-11-29"
author: "SpringDevPro Team"
tags: [spring-ai, architecture, core-concepts, design-patterns, deep-dive]
categories: [Spring AI, Architecture]
description: "Deep dive into Spring AI's architecture, design patterns, and core concepts. Learn how Spring AI works under the hood, from auto-configuration to advisors, with practical examples and best practices."
keywords: "spring ai architecture, spring ai design patterns, spring ai core concepts, spring ai internals, chatclient architecture"
featured_image: "images/spring-ai-architecture-featured.png"
reading_time: "28 min read"
difficulty: "Intermediate to Advanced"
---

# Complete Guide to Spring AI Architecture and Core Concepts

**Last Updated**: November 20, 2025  
**Reading Time**: 28 minutes  
**Difficulty**: Intermediate to Advanced  
**Code Examples**: [GitHub Repository](https://github.com/springdevpro/spring-ai-architecture-guide)

---

## Table of Contents

- [Complete Guide to Spring AI Architecture and Core Concepts](#complete-guide-to-spring-ai-architecture-and-core-concepts)
  - [Table of Contents](#table-of-contents)
  - [Introduction](#introduction)
  - [High-Level Architecture Overview](#high-level-architecture-overview)
    - [The Layered Architecture](#the-layered-architecture)
    - [The Request Flow](#the-request-flow)
    - [Module Structure](#module-structure)
    - [Design Philosophy](#design-philosophy)
  - [The Spring AI Stack](#the-spring-ai-stack)
    - [Layer 1: Core Abstractions (`spring-ai-core`)](#layer-1-core-abstractions-spring-ai-core)
    - [Layer 2: Provider Implementations](#layer-2-provider-implementations)
    - [Layer 3: Auto-Configuration](#layer-3-auto-configuration)
    - [Layer 4: ChatClient API](#layer-4-chatclient-api)
    - [Stack Integration Flow](#stack-integration-flow)
  - [Core Abstraction Layers](#core-abstraction-layers)
    - [Model Abstraction Hierarchy](#model-abstraction-hierarchy)
    - [Why This Abstraction Matters](#why-this-abstraction-matters)
    - [Request and Response Abstractions](#request-and-response-abstractions)
    - [Metadata Architecture](#metadata-architecture)
    - [Abstraction Trade-offs](#abstraction-trade-offs)
  - [ChatClient: The Fluent Interface](#chatclient-the-fluent-interface)
    - [ChatClient Architecture](#chatclient-architecture)
    - [Request Specification (Fluent Builder)](#request-specification-fluent-builder)
    - [Call Response Specification](#call-response-specification)
    - [Stream Response Specification](#stream-response-specification)
    - [Fluent API Examples](#fluent-api-examples)
    - [Internal Request Flow](#internal-request-flow)
    - [ChatClient Builder](#chatclient-builder)
  - [The Advisor Pattern](#the-advisor-pattern)
    - [What Are Advisors?](#what-are-advisors)
    - [Advisor Interface](#advisor-interface)
    - [Built-in Advisors](#built-in-advisors)
      - [1. MessageChatMemoryAdvisor](#1-messagechatmemoryadvisor)
      - [2. QuestionAnswerAdvisor (RAG)](#2-questionansweradvisor-rag)
    - [Custom Advisor Example](#custom-advisor-example)
    - [Advisor Execution Order](#advisor-execution-order)
  - [Model Abstractions](#model-abstractions)
    - [ChatModel Deep Dive](#chatmodel-deep-dive)
    - [EmbeddingModel Deep Dive](#embeddingmodel-deep-dive)
    - [ImageModel](#imagemodel)
    - [Multi-Modal Models](#multi-modal-models)
    - [Model Capabilities](#model-capabilities)
  - [Auto-Configuration Magic](#auto-configuration-magic)
    - [Auto-Configuration Classes](#auto-configuration-classes)
    - [Bean Creation Order](#bean-creation-order)
    - [Property Binding](#property-binding)
    - [Conditional Bean Creation](#conditional-bean-creation)
    - [Custom Configuration Override](#custom-configuration-override)
    - [Environment-Specific Configuration](#environment-specific-configuration)
  - [Metadata and Response Handling](#metadata-and-response-handling)
    - [ChatResponse Structure](#chatresponse-structure)
    - [Generation](#generation)
    - [ChatResponseMetadata](#chatresponsemetadata)
    - [ChatGenerationMetadata](#chatgenerationmetadata)
    - [Extracting Metadata](#extracting-metadata)
    - [Usage Tracking Service](#usage-tracking-service)
  - [Prompt Engineering Architecture](#prompt-engineering-architecture)
    - [PromptTemplate](#prompttemplate)
    - [Resource-Based Templates](#resource-based-templates)
    - [System Message Templates](#system-message-templates)
    - [Few-Shot Prompting](#few-shot-prompting)
    - [Structured Prompting](#structured-prompting)
  - [Vector Store Architecture](#vector-store-architecture)
    - [VectorStore Interface](#vectorstore-interface)
    - [SearchRequest](#searchrequest)
    - [Document Structure](#document-structure)
    - [Vector Store Implementations](#vector-store-implementations)
    - [Using Vector Stores](#using-vector-stores)
    - [Advanced: Hybrid Search](#advanced-hybrid-search)
  - [Document Processing Pipeline](#document-processing-pipeline)
    - [Document Readers](#document-readers)
    - [PDF Document Reader](#pdf-document-reader)
    - [Text Splitters](#text-splitters)
    - [Tika Document Reader](#tika-document-reader)
    - [Complete Document Processing Pipeline](#complete-document-processing-pipeline)
  - [Streaming and Reactive Support](#streaming-and-reactive-support)
    - [Streaming API](#streaming-api)
    - [Stream Response Spec](#stream-response-spec)
    - [Server-Sent Events (SSE) Controller](#server-sent-events-sse-controller)
    - [Reactive Operators](#reactive-operators)
  - [Function Calling Architecture](#function-calling-architecture)
    - [Function Callback](#function-callback)
    - [Defining Functions](#defining-functions)
    - [Using Functions](#using-functions)
    - [Function Calling Flow](#function-calling-flow)
    - [Complex Function Example](#complex-function-example)
  - [Structured Output Handling](#structured-output-handling)
    - [Entity Mapping](#entity-mapping)
    - [How It Works](#how-it-works)
    - [BeanOutputConverter](#beanoutputconverter)
    - [List of Entities](#list-of-entities)
    - [Validation](#validation)
  - [Error Handling and Resilience](#error-handling-and-resilience)
    - [Exception Hierarchy](#exception-hierarchy)
    - [Retry Configuration](#retry-configuration)
    - [Circuit Breaker](#circuit-breaker)
    - [Fallback Strategies](#fallback-strategies)
    - [Rate Limit Handling](#rate-limit-handling)
  - [Observability Architecture](#observability-architecture)
    - [Metrics](#metrics)
    - [Distributed Tracing](#distributed-tracing)
    - [Custom Observations](#custom-observations)
    - [Logging](#logging)
  - [Extensibility Points](#extensibility-points)
    - [1. Custom ChatModel](#1-custom-chatmodel)
    - [2. Custom VectorStore](#2-custom-vectorstore)
    - [3. Custom DocumentReader](#3-custom-documentreader)
    - [4. Custom Advisor](#4-custom-advisor)
  - [Spring AI Design Principles](#spring-ai-design-principles)
    - [1. Convention Over Configuration](#1-convention-over-configuration)
    - [2. Interface Segregation](#2-interface-segregation)
    - [3. Dependency Injection Everywhere](#3-dependency-injection-everywhere)
    - [4. Fail-Fast Validation](#4-fail-fast-validation)
    - [5. Immutability Where Possible](#5-immutability-where-possible)
    - [6. Composition Over Inheritance](#6-composition-over-inheritance)
    - [7. Progressive Disclosure](#7-progressive-disclosure)
  - [Performance Considerations](#performance-considerations)
    - [1. Connection Pooling](#1-connection-pooling)
    - [2. Async Processing](#2-async-processing)
    - [3. Caching](#3-caching)
    - [4. Batch Processing](#4-batch-processing)
    - [5. Token Management](#5-token-management)
    - [6. Streaming for Large Responses](#6-streaming-for-large-responses)
    - [7. Monitoring and Alerting](#7-monitoring-and-alerting)
  - [Advanced Architecture Patterns](#advanced-architecture-patterns)
    - [1. Multi-Model Strategy](#1-multi-model-strategy)
    - [2. Hierarchical RAG](#2-hierarchical-rag)
    - [3. Agent Pattern](#3-agent-pattern)
    - [4. Ensemble Pattern](#4-ensemble-pattern)
  - [Migration and Upgrade Strategies](#migration-and-upgrade-strategies)
    - [Migrating from LangChain4j](#migrating-from-langchain4j)
    - [Upgrading Spring AI Versions](#upgrading-spring-ai-versions)
  - [Conclusion](#conclusion)
    - [Key Takeaways](#key-takeaways)
    - [What's Next?](#whats-next)
    - [Further Resources](#further-resources)

---

## Introduction

Have you ever wondered how Spring AI makes AI integration feel so "Spring-like"? How does adding a single dependency and a few configuration lines give you a fully functional AI-powered application? What happens when you call `chatClient.prompt().user("Hello").call().content()`?

Understanding Spring AI's architecture isn't just academic curiosityâ€”it's practical knowledge that helps you:

- **Debug production issues faster**: Know where to look when things go wrong
- **Build custom integrations**: Extend Spring AI to fit your unique needs
- **Optimize performance**: Understand bottlenecks and how to address them
- **Make informed decisions**: Choose the right abstractions and patterns for your use case
- **Contribute to the project**: Understand the codebase structure

I've spent the last 8 months diving deep into Spring AI's internalsâ€”reading source code, debugging production issues, building custom advisors, and even contributing patches. This guide distills everything I learned about how Spring AI actually works under the hood.

**What makes this guide different**:

Rather than just describing components, we'll trace **real request flows** through the architecture. You'll see:

1. What happens when Spring Boot starts up and auto-configures Spring AI
2. The journey of a chat request from `ChatClient` to the AI provider and back
3. How advisors intercept and modify requests/responses
4. How streaming responses work with Project Reactor
5. How function calling is orchestrated
6. How RAG pipelines are constructed and executed

**Who this guide is for**:

- **Intermediate Spring developers** wanting to deeply understand Spring AI
- **Architects** designing Spring AI-based systems
- **Advanced users** building custom integrations or advisors
- **Contributors** wanting to understand the codebase

**Prerequisites**:

You should be comfortable with:
- Spring Boot fundamentals (dependency injection, auto-configuration)
- Basic AI/LLM concepts (prompts, tokens, embeddings)
- Java generics and functional programming
- (Optional) Project Reactor for reactive sections

If you're new to Spring AI, start with the [Quick Start Guide](https://springdevpro.com/spring-ai-quickstart) first.

Let's dive into the architecture ğŸ—ï¸

---

## High-Level Architecture Overview

Before diving into details, let's understand Spring AI's architecture at 30,000 feet.

### The Layered Architecture

Spring AI follows a classic layered architecture pattern, similar to Spring Data:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                             â”‚
â”‚            (Your business logic and controllers)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ChatClient API Layer                          â”‚
â”‚         (Fluent interface, advisors, prompt templates)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Abstraction Layer (Interfaces)                     â”‚
â”‚   ChatModel â”‚ EmbeddingModel â”‚ ImageModel â”‚ VectorStore ...     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Implementation Layer (Provider-specific)              â”‚
â”‚  OpenAI â”‚ Azure â”‚ Anthropic â”‚ Bedrock â”‚ Vertex AI â”‚ Ollama...  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Auto-Configuration Layer                          â”‚
â”‚     (Spring Boot auto-config, property binding, beans)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Infrastructure Layer                           â”‚
â”‚        (HTTP clients, retry logic, circuit breakers)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Architectural Principles**:

1. **Abstraction over Implementation**: Your code depends on interfaces (`ChatModel`, `EmbeddingModel`), not concrete implementations. This enables switching providers with configuration changes only.

2. **Dependency Injection Throughout**: Every component is a Spring bean, enabling testing, mocking, and runtime configuration.

3. **Auto-Configuration Magic**: Add a dependency, set propertiesâ€”Spring Boot wires everything automatically.

4. **Advisor Pattern for Cross-Cutting Concerns**: Memory, RAG, logging, metricsâ€”all implemented as advisors that wrap interactions.

5. **Reactive-Ready**: Core abstractions support both blocking and reactive (Project Reactor) programming models.

### The Request Flow

Let's trace a simple chat request through the architecture:

```java
// User code
String response = chatClient.prompt()
        .user("What is the capital of France?")
        .call()
        .content();
```

**What happens internally**:

```
1. ChatClient.prompt()
   â†“ Creates a ChatClientRequestSpec
   
2. user("What is the capital...")
   â†“ Adds user message to request
   
3. call()
   â†“ Builds ChatRequest
   â†“ Applies advisors (BEFORE_CALL)
   â†“   - MessageChatMemoryAdvisor adds conversation history
   â†“   - QuestionAnswerAdvisor searches vector store, adds context
   â†“   - Custom advisors run
   â†“ Delegates to ChatModel.call(ChatRequest)
   â†“   - OpenAiChatModel serializes to OpenAI API format
   â†“   - Sends HTTP request to api.openai.com
   â†“   - Receives and parses response
   â†“ Wraps in ChatResponse
   â†“ Applies advisors (AFTER_CALL)
   â†“   - MessageChatMemoryAdvisor stores response in memory
   â†“   - Observability advisors record metrics
   â†“ Returns ChatResponse
   
4. content()
   â†“ Extracts text content from ChatResponse
   â†“ Returns String to user
```

This flow reveals several key architectural components we'll explore in depth:

- **ChatClient**: Fluent API builder
- **Advisors**: Interceptors for cross-cutting concerns
- **ChatModel**: Abstraction over AI providers
- **ChatRequest/ChatResponse**: Request/response objects
- **Metadata**: Token usage, model info, finish reasons

### Module Structure

Spring AI is organized into several Maven modules:

```
spring-ai/
â”œâ”€â”€ spring-ai-core/                      # Core abstractions and APIs
â”‚   â”œâ”€â”€ ChatModel, EmbeddingModel interfaces
â”‚   â”œâ”€â”€ Document, Message classes
â”‚   â”œâ”€â”€ VectorStore interface
â”‚   â””â”€â”€ Prompt engineering utilities
â”‚
â”œâ”€â”€ spring-ai-spring-boot-autoconfigure/ # Auto-configuration
â”‚   â”œâ”€â”€ ChatClient auto-config
â”‚   â”œâ”€â”€ Provider auto-configs (OpenAI, Azure, etc.)
â”‚   â””â”€â”€ VectorStore auto-configs
â”‚
â”œâ”€â”€ spring-ai-openai/                    # OpenAI implementation
â”œâ”€â”€ spring-ai-azure-openai/              # Azure OpenAI implementation
â”œâ”€â”€ spring-ai-anthropic/                 # Anthropic Claude implementation
â”œâ”€â”€ spring-ai-vertex-ai-gemini/          # Google Gemini implementation
â”œâ”€â”€ spring-ai-bedrock/                   # AWS Bedrock implementations
â”œâ”€â”€ spring-ai-ollama/                    # Ollama (local models)
â”‚
â”œâ”€â”€ spring-ai-pgvector-store/            # PostgreSQL vector store
â”œâ”€â”€ spring-ai-redis-store/               # Redis vector store
â”œâ”€â”€ spring-ai-chroma-store/              # ChromaDB vector store
â”‚
â”œâ”€â”€ spring-ai-pdf-document-reader/       # PDF document processing
â”œâ”€â”€ spring-ai-tika-document-reader/      # Apache Tika integration
â”‚
â””â”€â”€ spring-ai-spring-boot-starters/      # Spring Boot starters
    â”œâ”€â”€ spring-ai-starter-openai/
    â”œâ”€â”€ spring-ai-starter-azure-openai/
    â””â”€â”€ ... (starter for each provider)
```

**Dependency Structure**:

When you add a starter:

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
</dependency>
```

You transitively get:
- `spring-ai-core` (abstractions)
- `spring-ai-openai` (OpenAI implementation)
- `spring-ai-spring-boot-autoconfigure` (auto-configuration)
- Spring Boot dependencies
- HTTP client dependencies (RestClient)

### Design Philosophy

Spring AI's architecture is guided by these principles:

**1. Portability Over Lock-In**

```java
// Your code depends on abstraction
@Service
public class MyService {
    private final ChatModel chatModel;  // Interface, not OpenAiChatModel
    
    // Switch from OpenAI to Azure by changing configuration only
    // No code changes needed!
}
```

**2. Convention Over Configuration**

```yaml
# Minimal configuration required
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
# Everything else auto-configured with sensible defaults
```

**3. Declarative Over Imperative**

```java
// Declarative advisor composition
ChatClient client = builder
        .defaultAdvisors(
            new MessageChatMemoryAdvisor(memory),
            new QuestionAnswerAdvisor(vectorStore)
        )
        .build();

// vs imperative (what other frameworks do)
// String context = vectorStore.search(query);
// String history = memory.get(userId);
// String prompt = buildPrompt(query, context, history);
// String response = model.call(prompt);
// memory.save(userId, response);
```

**4. Reactive-Compatible (Not Reactive-Required)**

```java
// Blocking API (default, simpler)
String response = chatClient.prompt().user("Hello").call().content();

// Reactive API (non-blocking, higher throughput)
Flux<String> stream = chatClient.prompt().user("Hello").stream().content();
```

Use reactive when you need it, blocking when you don't.

**5. Observability by Default**

Spring AI automatically emits metrics, traces, and logs. No manual instrumentation needed.

With this high-level understanding, let's dive into each architectural layer in detail.

---

## The Spring AI Stack

Let's understand how the different layers of the Spring AI stack work together.

### Layer 1: Core Abstractions (`spring-ai-core`)

The foundation of Spring AI. Defines interfaces and base classes used by all other modules.

**Key Interfaces**:

```java
package org.springframework.ai.chat.model;

/**
 * Core abstraction for chat/completion models.
 * Implementations: OpenAiChatModel, AnthropicChatModel, etc.
 */
public interface ChatModel extends Model<Prompt, ChatResponse> {
    
    /**
     * Synchronous call to AI model.
     * @param prompt The prompt with messages and options
     * @return ChatResponse with AI-generated content and metadata
     */
    ChatResponse call(Prompt prompt);
    
    /**
     * Reactive streaming call.
     * @param prompt The prompt
     * @return Flux of ChatResponse chunks (for streaming)
     */
    default Flux<ChatResponse> stream(Prompt prompt) {
        throw new UnsupportedOperationException("Streaming not supported");
    }
}
```

```java
package org.springframework.ai.embedding;

/**
 * Abstraction for embedding models.
 * Converts text to vector representations.
 */
public interface EmbeddingModel extends Model<EmbeddingRequest, EmbeddingResponse> {
    
    /**
     * Generate embeddings for text.
     * @param texts List of texts to embed
     * @return List of embedding vectors
     */
    EmbeddingResponse embedForResponse(List<String> texts);
    
    /**
     * Convenience method returning just the vectors.
     */
    default List<float[]> embed(List<String> texts) {
        return embedForResponse(texts).getResults().stream()
                .map(Embedding::getOutput)
                .collect(Collectors.toList());
    }
}
```

```java
package org.springframework.ai.vectorstore;

/**
 * Abstraction for vector databases.
 * Stores and retrieves embeddings.
 */
public interface VectorStore {
    
    /**
     * Add documents to vector store.
     * Documents are automatically embedded using configured EmbeddingModel.
     */
    void add(List<Document> documents);
    
    /**
     * Delete documents by ID.
     */
    Optional<Boolean> delete(List<String> idList);
    
    /**
     * Similarity search.
     * @param request Search parameters (query, topK, threshold)
     * @return Similar documents
     */
    List<Document> similaritySearch(SearchRequest request);
}
```

**Core Data Classes**:

```java
/**
 * Represents a message in a conversation.
 * Types: USER, ASSISTANT, SYSTEM, FUNCTION
 */
public class Message {
    private MessageType messageType;
    private String content;
    private Map<String, Object> metadata;
    
    // Factory methods
    public static Message user(String content) { ... }
    public static Message assistant(String content) { ... }
    public static Message system(String content) { ... }
}

/**
 * A prompt is a collection of messages with options.
 */
public class Prompt {
    private List<Message> messages;
    private ChatOptions options;  // Model, temperature, max tokens, etc.
    
    public Prompt(String userMessage) {
        this(List.of(new UserMessage(userMessage)));
    }
}

/**
 * Response from AI model.
 */
public class ChatResponse implements ModelResponse<Generation> {
    private List<Generation> results;      // Multiple generations if n > 1
    private ChatResponseMetadata metadata; // Token usage, model, finish reason
    
    // Convenience method to get first result
    public String getResult() {
        return results.get(0).getOutput().getContent();
    }
}

/**
 * A single generation (completion) from the model.
 */
public class Generation {
    private AssistantMessage output;  // The generated content
    private GenerationMetadata metadata;
}

/**
 * Represents a document with content and metadata.
 * Used in RAG and vector stores.
 */
public class Document {
    private String id;
    private String content;
    private Map<String, Object> metadata;
    private float[] embedding;  // Vector representation (optional)
    
    public Document(String content) {
        this(UUID.randomUUID().toString(), content, Map.of());
    }
}
```

### Layer 2: Provider Implementations

Each AI provider has its own module implementing the core abstractions.

**Example: OpenAI Implementation**

```java
package org.springframework.ai.openai;

public class OpenAiChatModel implements ChatModel {
    
    private final OpenAiApi openAiApi;  // HTTP client wrapper
    private final OpenAiChatOptions defaultOptions;
    private final RetryTemplate retryTemplate;
    private final ObservationRegistry observationRegistry;
    
    @Override
    public ChatResponse call(Prompt prompt) {
        
        // 1. Merge prompt options with defaults
        OpenAiChatOptions options = mergeOptions(
                prompt.getOptions(), 
                defaultOptions
        );
        
        // 2. Convert Spring AI Prompt to OpenAI API format
        OpenAiApi.ChatCompletionRequest request = 
                createRequest(prompt, options);
        
        // 3. Make HTTP call with retry and observability
        return retryTemplate.execute(context -> {
            Observation observation = startObservation();
            
            try {
                // Call OpenAI API
                OpenAiApi.ChatCompletion completion = 
                        openAiApi.chatCompletionEntity(request)
                                .getBody();
                
                // 4. Convert OpenAI response to Spring AI format
                return toChatResponse(completion);
                
            } finally {
                observation.stop();
            }
        });
    }
    
    @Override
    public Flux<ChatResponse> stream(Prompt prompt) {
        OpenAiApi.ChatCompletionRequest request = 
                createRequest(prompt, mergeOptions(...));
        
        // Use Server-Sent Events (SSE) for streaming
        return openAiApi.chatCompletionStream(request)
                .map(this::toChatResponse);
    }
    
    private ChatResponse toChatResponse(OpenAiApi.ChatCompletion completion) {
        // Map OpenAI response structure to Spring AI ChatResponse
        List<Generation> generations = completion.choices().stream()
                .map(choice -> new Generation(
                        new AssistantMessage(choice.message().content()),
                        ChatGenerationMetadata.from(choice)
                ))
                .toList();
        
        ChatResponseMetadata metadata = ChatResponseMetadata.builder()
                .withUsage(new DefaultUsage(
                        completion.usage().promptTokens(),
                        completion.usage().completionTokens()
                ))
                .withModel(completion.model())
                .withFinishReasons(completion.choices().stream()
                        .map(c -> c.finishReason())
                        .toList())
                .build();
        
        return new ChatResponse(generations, metadata);
    }
}
```

**Key Implementation Responsibilities**:

1. **API Client Wrapper**: HTTP client for provider's API
2. **Format Conversion**: Spring AI â†” Provider API formats
3. **Option Handling**: Map Spring AI options to provider-specific parameters
4. **Streaming Support**: Implement SSE/streaming if provider supports it
5. **Error Handling**: Map provider errors to Spring AI exceptions
6. **Observability**: Emit metrics and traces

### Layer 3: Auto-Configuration

Spring Boot auto-configuration wires everything together.

```java
package org.springframework.ai.autoconfigure.openai;

@AutoConfiguration
@ConditionalOnClass(OpenAiApi.class)
@EnableConfigurationProperties(OpenAiChatProperties.class)
public class OpenAiAutoConfiguration {
    
    /**
     * Create OpenAI API client bean.
     */
    @Bean
    @ConditionalOnMissingBean
    public OpenAiApi openAiApi(OpenAiChatProperties properties) {
        return new OpenAiApi(
                properties.getBaseUrl(),
                properties.getApiKey(),
                RestClient.builder()
        );
    }
    
    /**
     * Create OpenAI ChatModel bean.
     */
    @Bean
    @ConditionalOnMissingBean(ChatModel.class)
    public OpenAiChatModel openAiChatModel(
            OpenAiApi openAiApi,
            OpenAiChatProperties properties,
            @Autowired(required = false) ObservationRegistry observationRegistry) {
        
        return new OpenAiChatModel(
                openAiApi,
                properties.getChat().getOptions(),
                RetryTemplate.builder()
                        .maxAttempts(properties.getRetry().getMaxAttempts())
                        .exponentialBackoff(
                                properties.getRetry().getBackoff().getInitialInterval(),
                                properties.getRetry().getBackoff().getMultiplier(),
                                properties.getRetry().getBackoff().getMaxInterval()
                        )
                        .build(),
                observationRegistry
        );
    }
    
    /**
     * Create ChatClient.Builder bean.
     */
    @Bean
    @ConditionalOnMissingBean
    public ChatClient.Builder chatClientBuilder(ChatModel chatModel) {
        return ChatClient.builder(chatModel);
    }
}
```

**Configuration Properties**:

```java
@ConfigurationProperties("spring.ai.openai")
public class OpenAiChatProperties {
    
    private String apiKey;
    private String baseUrl = "https://api.openai.com";
    
    private ChatOptions chat = new ChatOptions();
    private RetryOptions retry = new RetryOptions();
    
    public static class ChatOptions {
        private String model = "gpt-3.5-turbo";
        private Double temperature = 0.7;
        private Integer maxTokens;
        // ... other options
    }
    
    public static class RetryOptions {
        private int maxAttempts = 3;
        private BackoffOptions backoff = new BackoffOptions();
    }
}
```

Maps to `application.yml`:

```yaml
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      base-url: https://api.openai.com
      chat:
        options:
          model: gpt-4o
          temperature: 0.7
          max-tokens: 1000
      retry:
        max-attempts: 5
        backoff:
          initial-interval: 2s
          multiplier: 2
          max-interval: 10s
```

### Layer 4: ChatClient API

The fluent interface layer that developers interact with.

```java
package org.springframework.ai.chat.client;

/**
 * Fluent API for building and executing AI chat requests.
 * 
 * Example:
 *   chatClient.prompt()
 *       .system("You are a helpful assistant")
 *       .user("What is Spring?")
 *       .call()
 *       .content();
 */
public interface ChatClient {
    
    /**
     * Start building a chat request.
     */
    ChatClientRequestSpec prompt();
    
    /**
     * Start building a chat request with initial user message.
     */
    default ChatClientRequestSpec prompt(String userMessage) {
        return prompt().user(userMessage);
    }
    
    /**
     * Builder for creating ChatClient instances.
     */
    interface Builder {
        Builder defaultSystem(String systemText);
        Builder defaultAdvisors(RequestResponseAdvisor... advisors);
        Builder defaultOptions(ChatOptions options);
        ChatClient build();
    }
    
    static Builder builder(ChatModel chatModel) {
        return new DefaultChatClientBuilder(chatModel);
    }
}
```

**Internal Architecture** (simplified):

```java
class DefaultChatClient implements ChatClient {
    
    private final ChatModel chatModel;
    private final String defaultSystemText;
    private final List<RequestResponseAdvisor> defaultAdvisors;
    private final ChatOptions defaultOptions;
    
    @Override
    public ChatClientRequestSpec prompt() {
        return new DefaultChatClientRequestSpec(this);
    }
    
    // Called by ChatClientRequestSpec.call()
    ChatResponse executeRequest(ChatClientRequest request) {
        
        // 1. Build prompt from request
        Prompt prompt = buildPrompt(request);
        
        // 2. Apply BEFORE_CALL advisors
        AdvisedRequest advisedRequest = applyBeforeAdvisors(
                request, 
                prompt
        );
        
        // 3. Call underlying ChatModel
        ChatResponse response = chatModel.call(advisedRequest.prompt());
        
        // 4. Apply AFTER_CALL advisors
        ChatResponse advisedResponse = applyAfterAdvisors(
                advisedRequest,
                response
        );
        
        return advisedResponse;
    }
}
```

### Stack Integration Flow

Here's how all layers work together when you make a request:

```
Application Code:
  chatClient.prompt().user("Hello").call().content()
    â†“
ChatClient (Layer 4):
  - Builds ChatClientRequest from fluent API
  - Creates Prompt with messages and options
    â†“
Advisor Framework (Layer 4):
  - Runs BEFORE_CALL advisors
  - MessageChatMemoryAdvisor adds history
  - QuestionAnswerAdvisor adds RAG context
  - Modifies Prompt
    â†“
ChatModel Abstraction (Layer 1):
  - call(Prompt) invoked
    â†“
Provider Implementation (Layer 2):
  - OpenAiChatModel receives call
  - Converts Prompt to OpenAI API format
  - Applies retry template
  - Starts observability tracking
    â†“
HTTP Client:
  - Sends POST to api.openai.com/v1/chat/completions
  - Receives JSON response
    â†“
Provider Implementation (Layer 2):
  - Parses OpenAI response
  - Converts to ChatResponse
  - Extracts token usage, model, finish reason
    â†“
Advisor Framework (Layer 4):
  - Runs AFTER_CALL advisors
  - MessageChatMemoryAdvisor stores response
  - Observability advisors record metrics
    â†“
ChatClient (Layer 4):
  - Returns ChatResponse to application
    â†“
Application Code:
  - Extracts content: response.content()
  - Returns String to user
```

ğŸ’¡ **Key Insight**: Spring AI's layered architecture provides:

1. **Separation of Concerns**: Each layer has a clear responsibility
2. **Extensibility**: Add new providers by implementing Layer 2
3. **Testability**: Mock at any layer (ChatModel, ChatClient, etc.)
4. **Portability**: Switch providers without changing application code
5. **Observability**: Instrumentation at multiple layers

Now that we understand the overall stack, let's dive deeper into each component.

---

## Core Abstraction Layers

Let's examine Spring AI's core abstractions in detailâ€”the interfaces that enable portability.

### Model Abstraction Hierarchy

```java
/**
 * Root interface for all AI models.
 * Generic over request and response types.
 */
public interface Model<I extends ModelRequest<?>, O extends ModelResponse<?>> {
    
    O call(I request);
    
    default Flux<O> stream(I request) {
        throw new UnsupportedOperationException("Streaming not supported");
    }
}
```

**Specialized Model Interfaces**:

```java
// Chat/Completion models (GPT, Claude, Gemini)
public interface ChatModel extends Model<Prompt, ChatResponse> {
    ChatResponse call(Prompt prompt);
    default Flux<ChatResponse> stream(Prompt prompt) { ... }
}

// Embedding models (text-embedding-ada-002, etc.)
public interface EmbeddingModel extends Model<EmbeddingRequest, EmbeddingResponse> {
    EmbeddingResponse embedForResponse(List<String> texts);
}

// Image generation models (DALL-E, Stable Diffusion)
public interface ImageModel extends Model<ImagePrompt, ImageResponse> {
    ImageResponse call(ImagePrompt request);
}

// Audio models (Whisper, TTS)
public interface AudioTranscriptionModel extends Model<AudioTranscriptionPrompt, AudioTranscriptionResponse> {
    AudioTranscriptionResponse call(AudioTranscriptionPrompt request);
}

public interface AudioSpeechModel extends Model<SpeechPrompt, SpeechResponse> {
    SpeechResponse call(SpeechPrompt prompt);
}

// Moderation models
public interface ModerationModel extends Model<ModerationPrompt, ModerationResponse> {
    ModerationResponse call(ModerationPrompt request);
}
```

### Why This Abstraction Matters

**Example: Provider-Agnostic Service**

```java
@Service
public class DocumentAnalysisService {
    
    // Depends on abstraction, not implementation
    private final ChatModel chatModel;  // Could be OpenAI, Claude, Gemini
    private final EmbeddingModel embeddingModel;  // Could be any provider
    private final VectorStore vectorStore;  // Could be PGVector, ChromaDB, etc.
    
    public DocumentAnalysisService(
            ChatModel chatModel,
            EmbeddingModel embeddingModel,
            VectorStore vectorStore) {
        this.chatModel = chatModel;
        this.embeddingModel = embeddingModel;
        this.vectorStore = vectorStore;
    }
    
    public String analyzeDocument(String document, String question) {
        // 1. Split document into chunks
        List<String> chunks = splitDocument(document);
        
        // 2. Create embeddings (works with any EmbeddingModel)
        List<float[]> embeddings = embeddingModel.embed(chunks);
        
        // 3. Store in vector database (works with any VectorStore)
        List<Document> docs = IntStream.range(0, chunks.size())
                .mapToObj(i -> new Document(chunks.get(i)))
                .toList();
        vectorStore.add(docs);
        
        // 4. Retrieve relevant chunks
        List<Document> relevantDocs = vectorStore.similaritySearch(
                SearchRequest.query(question).withTopK(3)
        );
        
        // 5. Generate answer (works with any ChatModel)
        String context = relevantDocs.stream()
                .map(Document::getContent)
                .collect(Collectors.joining("\n\n"));
        
        return chatModel.call(new Prompt("""
                Based on this context:
                %s
                
                Answer this question: %s
                """.formatted(context, question)))
                .getResult();
    }
}
```

**Switch providers with configuration only**:

```yaml
# Use OpenAI
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
```

```yaml
# Switch to Anthropic Claude - NO CODE CHANGES
spring:
  ai:
    anthropic:
      api-key: ${ANTHROPIC_API_KEY}
```

Spring Boot auto-configuration detects which starter is on the classpath and wires the appropriate implementation.

### Request and Response Abstractions

**Prompt**: The request to a chat model

```java
public class Prompt implements ModelRequest<List<Message>> {
    
    private final List<Message> messages;
    private final ChatOptions chatOptions;
    
    // Simple constructor - one user message
    public Prompt(String contents) {
        this(new UserMessage(contents));
    }
    
    // Full constructor - multiple messages
    public Prompt(List<Message> messages) {
        this(messages, ChatOptionsBuilder.builder().build());
    }
    
    // With options (temperature, max tokens, etc.)
    public Prompt(List<Message> messages, ChatOptions chatOptions) {
        this.messages = messages;
        this.chatOptions = chatOptions;
    }
    
    @Override
    public List<Message> getInstructions() {
        return this.messages;
    }
    
    @Override
    public ChatOptions getOptions() {
        return this.chatOptions;
    }
}
```

**Message**: A single message in the conversation

```java
public abstract class Message {
    
    private final MessageType messageType;
    private final String content;
    private final Map<String, Object> metadata;
    
    public enum MessageType {
        USER,      // Message from user
        ASSISTANT, // Message from AI
        SYSTEM,    // System instruction (controls behavior)
        FUNCTION,  // Result of function call
        TOOL       // Tool invocation/result
    }
}

// Concrete message types
public class UserMessage extends Message {
    public UserMessage(String content) {
        super(MessageType.USER, content);
    }
    
    public UserMessage(String content, Map<String, Object> metadata) {
        super(MessageType.USER, content, metadata);
    }
}

public class AssistantMessage extends Message {
    private final List<ToolCall> toolCalls;  // For function calling
    
    public AssistantMessage(String content) {
        super(MessageType.ASSISTANT, content);
    }
}

public class SystemMessage extends Message {
    public SystemMessage(String content) {
        super(MessageType.SYSTEM, content);
    }
}
```

**ChatResponse**: The response from a chat model

```java
public class ChatResponse implements ModelResponse<Generation> {
    
    private final List<Generation> generations;
    private final ChatResponseMetadata metadata;
    
    public ChatResponse(List<Generation> generations) {
        this(generations, ChatResponseMetadata.empty());
    }
    
    public ChatResponse(List<Generation> generations, ChatResponseMetadata metadata) {
        this.generations = generations;
        this.metadata = metadata;
    }
    
    @Override
    public List<Generation> getResults() {
        return this.generations;
    }
    
    @Override
    public ChatResponseMetadata getMetadata() {
        return this.metadata;
    }
    
    // Convenience method - get first generation's content
    public Generation getResult() {
        return this.generations.get(0);
    }
}

/**
 * A single generated response.
 * If you request n=3 completions, you get 3 Generation objects.
 */
public class Generation implements ModelResult<AssistantMessage> {
    
    private final AssistantMessage assistantMessage;
    private final ChatGenerationMetadata metadata;
    
    @Override
    public AssistantMessage getOutput() {
        return this.assistantMessage;
    }
    
    @Override
    public ChatGenerationMetadata getMetadata() {
        return this.metadata;
    }
}
```

**ChatOptions**: Model configuration

```java
public interface ChatOptions {
    String getModel();
    Double getTemperature();
    Integer getMaxTokens();
    Double getTopP();
    Integer getTopK();
    Double getFrequencyPenalty();
    Double getPresencePenalty();
    List<String> getStopSequences();
    // ... more options
}

// Builder for options
ChatOptions options = ChatOptionsBuilder.builder()
        .withModel("gpt-4o")
        .withTemperature(0.7)
        .withMaxTokens(1000)
        .build();
```

### Metadata Architecture

Every response includes rich metadata:

```java
public class ChatResponseMetadata {
    
    private final String id;                    // Response ID
    private final String model;                 // Model used
    private final Usage usage;                  // Token counts
    private final RateLimit rateLimit;          // Rate limit info
    private final List<String> finishReasons;   // Why generation stopped
    
    /**
     * Token usage information.
     */
    public interface Usage {
        Long getPromptTokens();
        Long getGenerationTokens();
        Long getTotalTokens();
    }
    
    /**
     * Rate limit information.
     */
    public interface RateLimit {
        Long getRequestsLimit();
        Long getRequestsRemaining();
        Long getTokensLimit();
        Long getTokensRemaining();
        Duration getRequestsReset();
        Duration getTokensReset();
    }
}
```

**Usage Example**:

```java
ChatResponse response = chatClient.prompt()
        .user("Explain quantum computing")
        .call()
        .chatResponse();

// Access metadata
ChatResponseMetadata metadata = response.getMetadata();

System.out.println("Model: " + metadata.getModel());
System.out.println("Prompt tokens: " + metadata.getUsage().getPromptTokens());
System.out.println("Completion tokens: " + metadata.getUsage().getGenerationTokens());
System.out.println("Total tokens: " + metadata.getUsage().getTotalTokens());
System.out.println("Finish reason: " + metadata.getFinishReasons().get(0));

// Calculate cost (OpenAI pricing)
long totalTokens = metadata.getUsage().getTotalTokens();
double cost = (totalTokens / 1000.0) * 0.002; // $0.002 per 1K tokens
System.out.println("Cost: $" + cost);
```

ğŸ’¡ **Architecture Benefit**: Consistent metadata across all providers. OpenAI, Claude, Geminiâ€”all return the same metadata structure, making billing, monitoring, and analytics provider-agnostic.

### Abstraction Trade-offs

**Benefits**:
- âœ… Switch providers without code changes
- âœ… Test with mock implementations
- âœ… Multi-provider support in same app
- âœ… Consistent error handling
- âœ… Unified observability

**Limitations**:
- âš ï¸ Lowest-common-denominator: Only features supported by all providers
- âš ï¸ Provider-specific features require casting to concrete types
- âš ï¸ Small performance overhead (negligible in practice)

**Example: Using Provider-Specific Features**:

```java
// General abstraction
ChatModel chatModel = ...;  // Could be any provider

// Need OpenAI-specific feature (e.g., function calling with tools)
if (chatModel instanceof OpenAiChatModel openAiModel) {
    // Use OpenAI-specific options
    OpenAiChatOptions options = OpenAiChatOptions.builder()
            .withTools(List.of(myTool))  // OpenAI-specific
            .build();
    
    ChatResponse response = openAiModel.call(
            new Prompt("Use the calculator", options)
    );
}
```

Spring AI balances abstraction with provider-specific features well.

---

## ChatClient: The Fluent Interface

`ChatClient` is the primary API developers interact with. Let's understand its architecture.

### ChatClient Architecture

```java
public interface ChatClient {
    
    /**
     * Start building a chat request.
     * Returns a request specification (fluent builder).
     */
    ChatClientRequestSpec prompt();
    
    default ChatClientRequestSpec prompt(String userText) {
        return prompt().user(userText);
    }
    
    /**
     * Builder for creating configured ChatClient instances.
     */
    interface Builder {
        Builder defaultSystem(String systemText);
        Builder defaultSystem(Resource systemResource);
        Builder defaultOptions(ChatOptions options);
        Builder defaultAdvisors(RequestResponseAdvisor... advisors);
        Builder defaultAdvisors(List<RequestResponseAdvisor> advisors);
        ChatClient build();
    }
    
    static Builder builder(ChatModel chatModel) {
        return new DefaultChatClientBuilder(chatModel);
    }
}
```

### Request Specification (Fluent Builder)

```java
public interface ChatClientRequestSpec {
    
    // ===== Message Building =====
    
    /**
     * Add system message (instructions that control behavior).
     */
    ChatClientRequestSpec system(String text);
    ChatClientRequestSpec system(Resource resource);
    ChatClientRequestSpec system(Consumer<SystemSpec> systemSpecConsumer);
    
    /**
     * Add user message.
     */
    ChatClientRequestSpec user(String text);
    ChatClientRequestSpec user(Resource resource);
    ChatClientRequestSpec user(Consumer<UserSpec> userSpecConsumer);
    
    /**
     * Add assistant message (for few-shot examples).
     */
    ChatClientRequestSpec assistant(String text);
    
    /**
     * Add all messages from previous conversation.
     */
    ChatClientRequestSpec messages(List<Message> messages);
    ChatClientRequestSpec messages(Message... messages);
    
    // ===== Options & Configuration =====
    
    /**
     * Override options for this request.
     */
    ChatClientRequestSpec options(ChatOptions options);
    
    /**
     * Add advisors for this request (in addition to defaults).
     */
    ChatClientRequestSpec advisors(RequestResponseAdvisor... advisors);
    ChatClientRequestSpec advisors(Consumer<AdvisorSpec> advisorSpecConsumer);
    
    /**
     * Add function callbacks (for function calling).
     */
    ChatClientRequestSpec function(String name, String description, 
                                    BiFunction<?, ?, ?> function);
    ChatClientRequestSpec functions(FunctionCallback... functionCallbacks);
    
    // ===== Execution =====
    
    /**
     * Execute and return full ChatResponse.
     */
    CallResponseSpec call();
    
    /**
     * Execute with streaming.
     */
    StreamResponseSpec stream();
}
```

### Call Response Specification

```java
public interface CallResponseSpec {
    
    /**
     * Get the full ChatResponse with metadata.
     */
    ChatResponse chatResponse();
    
    /**
     * Get just the text content (most common).
     */
    String content();
    
    /**
     * Get entity - deserialize response to Java object.
     */
    <T> T entity(Class<T> entityClass);
    <T> T entity(ParameterizedTypeReference<T> entityType);
}
```

### Stream Response Specification

```java
public interface StreamResponseSpec {
    
    /**
     * Stream ChatResponse chunks.
     */
    Flux<ChatResponse> chatResponse();
    
    /**
     * Stream just content strings.
     */
    Flux<String> content();
    
    /**
     * Stream entities (for structured streaming).
     */
    <T> Flux<T> entity(Class<T> entityClass);
    <T> Flux<T> entity(ParameterizedTypeReference<T> entityType);
}
```

### Fluent API Examples

**Simple Chat**:

```java
String response = chatClient.prompt()
        .user("What is the capital of France?")
        .call()
        .content();
```

**With System Instructions**:

```java
String response = chatClient.prompt()
        .system("You are a helpful French tutor. Always respond with encouragement.")
        .user("How do I say 'hello' in French?")
        .call()
        .content();
```

**With Options Override**:

```java
String response = chatClient.prompt()
        .user("Write a creative story about a robot")
        .options(ChatOptionsBuilder.builder()
                .withTemperature(1.5)  // More creative
                .withMaxTokens(500)
                .build())
        .call()
        .content();
```

**Streaming Response**:

```java
Flux<String> stream = chatClient.prompt()
        .user("Explain quantum mechanics in detail")
        .stream()
        .content();

stream.subscribe(chunk -> System.out.print(chunk));
```

**Structured Output**:

```java
record WeatherInfo(String location, int temperature, String condition) {}

WeatherInfo weather = chatClient.prompt()
        .user("What's the weather in Paris?")
        .call()
        .entity(WeatherInfo.class);

System.out.println("Temperature: " + weather.temperature() + "Â°C");
```

**With Function Calling**:

```java
@Component
public class Calculator {
    
    @Bean
    @Description("Add two numbers")
    public Function<AddRequest, Integer> add() {
        return request -> request.a() + request.b();
    }
    
    record AddRequest(int a, int b) {}
}

String response = chatClient.prompt()
        .user("What is 1234 + 5678?")
        .function("add", "Add two numbers", calculator.add())
        .call()
        .content();
// AI will call the function and incorporate result into response
```

### Internal Request Flow

Let's trace what happens internally when you build and execute a request:

```java
// User code
String content = chatClient.prompt()
        .system("Be concise")
        .user("Hello")
        .call()
        .content();
```

**Step 1: prompt()** creates DefaultChatClientRequestSpec:

```java
class DefaultChatClientRequestSpec implements ChatClientRequestSpec {
    
    private final DefaultChatClient chatClient;
    private final List<Message> messages = new ArrayList<>();
    private ChatOptions chatOptions;
    private List<RequestResponseAdvisor> advisors = new ArrayList<>();
    private List<FunctionCallback> functionCallbacks = new ArrayList<>();
    
    DefaultChatClientRequestSpec(DefaultChatClient chatClient) {
        this.chatClient = chatClient;
    }
}
```

**Step 2: system("Be concise")** adds SystemMessage:

```java
@Override
public ChatClientRequestSpec system(String text) {
    this.messages.add(new SystemMessage(text));
    return this;
}
```

**Step 3: user("Hello")** adds UserMessage:

```java
@Override
public ChatClientRequestSpec user(String text) {
    this.messages.add(new UserMessage(text));
    return this;
}
```

**Step 4: call()** creates CallResponseSpec:

```java
@Override
public CallResponseSpec call() {
    return new DefaultCallResponseSpec(this.chatClient, buildRequest());
}

private ChatClientRequest buildRequest() {
    return ChatClientRequest.builder()
            .messages(this.messages)
            .options(this.chatOptions)
            .advisors(this.advisors)
            .functionCallbacks(this.functionCallbacks)
            .build();
}
```

**Step 5: content()** executes request:

```java
class DefaultCallResponseSpec implements CallResponseSpec {
    
    private final DefaultChatClient chatClient;
    private final ChatClientRequest request;
    
    @Override
    public String content() {
        ChatResponse response = chatClient.executeRequest(request);
        return response.getResult().getOutput().getContent();
    }
}
```

**Step 6: chatClient.executeRequest()** orchestrates execution:

```java
ChatResponse executeRequest(ChatClientRequest request) {
    
    // 1. Merge messages (defaults + request-specific)
    List<Message> allMessages = new ArrayList<>();
    if (defaultSystemText != null) {
        allMessages.add(new SystemMessage(defaultSystemText));
    }
    allMessages.addAll(request.messages());
    
    // 2. Merge options
    ChatOptions options = mergeOptions(defaultOptions, request.options());
    
    // 3. Create Prompt
    Prompt prompt = new Prompt(allMessages, options);
    
    // 4. Merge advisors
    List<RequestResponseAdvisor> allAdvisors = new ArrayList<>();
    allAdvisors.addAll(defaultAdvisors);
    allAdvisors.addAll(request.advisors());
    
    // 5. Apply BEFORE_CALL advisors
    AdvisedRequest advisedRequest = new AdvisedRequest(prompt, request.userParams());
    for (RequestResponseAdvisor advisor : allAdvisors) {
        advisedRequest = advisor.adviseRequest(advisedRequest, request.adviseContext());
    }
    
    // 6. Call ChatModel
    ChatResponse response = chatModel.call(advisedRequest.prompt());
    
    // 7. Apply AFTER_CALL advisors
    for (RequestResponseAdvisor advisor : allAdvisors) {
        response = advisor.adviseResponse(advisedRequest, response, request.adviseContext());
    }
    
    return response;
}
```

ğŸ’¡ **Key Insight**: The fluent API is just a builder pattern. The real work happens in `executeRequest()` which orchestrates advisors and delegates to `ChatModel`.

### ChatClient Builder

Create customized ChatClient instances with defaults:

```java
@Configuration
public class ChatClientConfig {
    
    @Bean
    public ChatClient customerSupportChatClient(
            ChatModel chatModel,
            VectorStore vectorStore,
            ChatMemory chatMemory) {
        
        return ChatClient.builder(chatModel)
                .defaultSystem("""
                    You are a helpful customer support agent for Acme Corp.
                    Be professional, empathetic, and concise.
                    If you don't know something, admit it honestly.
                    """)
                .defaultOptions(ChatOptionsBuilder.builder()
                        .withTemperature(0.3)  // More deterministic
                        .withMaxTokens(300)
                        .build())
                .defaultAdvisors(
                        new MessageChatMemoryAdvisor(chatMemory),
                        new QuestionAnswerAdvisor(vectorStore, SearchRequest.defaults())
                )
                .build();
    }
    
    @Bean
    public ChatClient creativeChatClient(ChatModel chatModel) {
        return ChatClient.builder(chatModel)
                .defaultSystem("You are a creative writing assistant.")
                .defaultOptions(ChatOptionsBuilder.builder()
                        .withTemperature(1.2)  // More creative
                        .withMaxTokens(1000)
                        .build())
                .build();
    }
}
```

Now you have multiple ChatClient beans with different configurations:

```java
@Service
public class ChatService {
    
    @Qualifier("customerSupportChatClient")
    private final ChatClient supportClient;
    
    @Qualifier("creativeChatClient")
    private final ChatClient creativeClient;
    
    public String handleSupport(String question) {
        return supportClient.prompt(question).call().content();
    }
    
    public String generateStory(String prompt) {
        return creativeClient.prompt(prompt).call().content();
    }
}
```

ğŸ’¡ **Architecture Benefit**: One ChatModel, multiple ChatClient configurations. Efficient resource usage with specialized behaviors.

---

## The Advisor Pattern

Advisors are Spring AI's mechanism for cross-cutting concernsâ€”the AOP (Aspect-Oriented Programming) of AI interactions.

### What Are Advisors?

**Advisors intercept requests and responses to add functionality**:

- **Memory**: Add conversation history to prompts
- **RAG**: Retrieve relevant documents and inject as context
- **Logging**: Log all interactions
- **Metrics**: Track usage, latency, costs
- **Safety**: Content moderation, PII redaction
- **Rate Limiting**: Control API usage
- **Retry**: Handle transient failures

### Advisor Interface

```java
package org.springframework.ai.chat.client.advisor;

/**
 * Advisor that can modify requests before calling the model
 * and/or responses after receiving them.
 */
public interface RequestResponseAdvisor {
    
    /**
     * Modify the request before it's sent to the model.
     * 
     * @param request The original request
     * @param context Additional context
     * @return Modified request
     */
    AdvisedRequest adviseRequest(
            AdvisedRequest request, 
            Map<String, Object> context
    );
    
    /**
     * Modify the response after receiving from model.
     * 
     * @param request The request that was sent
     * @param response The response received
     * @param context Additional context
     * @return Modified response
     */
    ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context
    );
    
    /**
     * Name of this advisor (for debugging).
     */
    default String getName() {
        return this.getClass().getSimpleName();
    }
    
    /**
     * Order for advisor execution (lower runs first).
     */
    default int getOrder() {
        return 0;
    }
}
```

**AdvisedRequest**: Wrapper around Prompt with extra data:

```java
public class AdvisedRequest {
    
    private final Prompt prompt;                 // The actual prompt
    private final Map<String, Object> userParams;  // User-provided data
    
    // Convenience method to update prompt
    public AdvisedRequest updatePrompt(Prompt newPrompt) {
        return new AdvisedRequest(newPrompt, this.userParams);
    }
}
```

### Built-in Advisors

#### 1. MessageChatMemoryAdvisor

Adds conversation history to each request:

```java
public class MessageChatMemoryAdvisor implements RequestResponseAdvisor {
    
    private final ChatMemory chatMemory;
    private final String conversationId;
    
    public MessageChatMemoryAdvisor(ChatMemory chatMemory) {
        this(chatMemory, DEFAULT_CONVERSATION_ID);
    }
    
    @Override
    public AdvisedRequest adviseRequest(AdvisedRequest request, Map<String, Object> context) {
        
        String conversationId = getConversationId(context);
        
        // 1. Get conversation history from memory
        List<Message> historyMessages = chatMemory.get(conversationId);
        
        // 2. Combine history + new messages
        List<Message> allMessages = new ArrayList<>();
        allMessages.addAll(historyMessages);
        allMessages.addAll(request.prompt().getInstructions());
        
        // 3. Create new prompt with history
        Prompt newPrompt = new Prompt(
                allMessages,
                request.prompt().getOptions()
        );
        
        return request.updatePrompt(newPrompt);
    }
    
    @Override
    public ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context) {
        
        String conversationId = getConversationId(context);
        
        // Store user message
        List<Message> userMessages = request.prompt().getInstructions();
        chatMemory.add(conversationId, userMessages);
        
        // Store assistant response
        List<Message> assistantMessages = response.getResults().stream()
                .map(Generation::getOutput)
                .collect(Collectors.toList());
        chatMemory.add(conversationId, assistantMessages);
        
        return response;
    }
}
```

**Usage**:

```java
ChatMemory memory = new InMemoryChatMemory();

ChatClient client = ChatClient.builder(chatModel)
        .defaultAdvisors(new MessageChatMemoryAdvisor(memory))
        .build();

// First turn
client.prompt().user("My name is Alice").call().content();
// Response: "Hello Alice! How can I help you?"

// Second turn - model remembers context
client.prompt().user("What's my name?").call().content();
// Response: "Your name is Alice."
```

#### 2. QuestionAnswerAdvisor (RAG)

Retrieves relevant documents and adds them as context:

```java
public class QuestionAnswerAdvisor implements RequestResponseAdvisor {
    
    private final VectorStore vectorStore;
    private final SearchRequest searchRequest;
    private final String userTextAdvise;
    
    public QuestionAnswerAdvisor(VectorStore vectorStore, SearchRequest searchRequest) {
        this.vectorStore = vectorStore;
        this.searchRequest = searchRequest;
        this.userTextAdvise = """
                Context information is below.
                ---------------------
                {context}
                ---------------------
                Given the context information and not prior knowledge,
                answer the query.
                Query: {query}
                Answer:
                """;
    }
    
    @Override
    public AdvisedRequest adviseRequest(AdvisedRequest request, Map<String, Object> context) {
        
        // 1. Extract user question
        List<Message> messages = request.prompt().getInstructions();
        Message lastMessage = messages.get(messages.size() - 1);
        
        if (!(lastMessage instanceof UserMessage userMessage)) {
            return request;  // No user message, skip RAG
        }
        
        String query = userMessage.getContent();
        
        // 2. Search vector store for relevant documents
        SearchRequest searchRequestToUse = SearchRequest.from(searchRequest)
                .withQuery(query);
        
        List<Document> documents = vectorStore.similaritySearch(searchRequestToUse);
        
        // 3. Build context from documents
        String documentContext = documents.stream()
                .map(Document::getContent)
                .collect(Collectors.joining("\n\n"));
        
        // 4. Create augmented prompt
        String augmentedUserText = userTextAdvise
                .replace("{context}", documentContext)
                .replace("{query}", query);
        
        // 5. Replace user message with augmented version
        List<Message> newMessages = new ArrayList<>(messages);
        newMessages.set(newMessages.size() - 1, 
                new UserMessage(augmentedUserText));
        
        Prompt newPrompt = new Prompt(
                newMessages,
                request.prompt().getOptions()
        );
        
        // 6. Store retrieved documents in context (for debugging/citation)
        context.put("rag_documents", documents);
        
        return request.updatePrompt(newPrompt);
    }
    
    @Override
    public ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context) {
        
        // Could add citations to response metadata here
        return response;
    }
}
```

**Usage**:

```java
VectorStore vectorStore = ...; // Pre-populated with documentation

ChatClient client = ChatClient.builder(chatModel)
        .defaultAdvisors(
                new QuestionAnswerAdvisor(
                        vectorStore,
                        SearchRequest.defaults().withTopK(3)
                )
        )
        .build();

String answer = client.prompt()
        .user("How do I configure Spring Security?")
        .call()
        .content();

// Behind the scenes:
// 1. QuestionAnswerAdvisor searches vectorStore
// 2. Finds 3 relevant documentation chunks
// 3. Adds them as context to the prompt
// 4. Model answers based on provided context
```

### Custom Advisor Example

Let's build a custom advisor that redacts PII (Personally Identifiable Information):

```java
@Component
public class PiiRedactionAdvisor implements RequestResponseAdvisor {
    
    private static final Pattern EMAIL_PATTERN = 
            Pattern.compile("\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b");
    
    private static final Pattern PHONE_PATTERN = 
            Pattern.compile("\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b");
    
    private static final Pattern SSN_PATTERN = 
            Pattern.compile("\\b\\d{3}-\\d{2}-\\d{4}\\b");
    
    @Override
    public AdvisedRequest adviseRequest(AdvisedRequest request, Map<String, Object> context) {
        
        // Redact PII from user messages before sending to AI
        List<Message> redactedMessages = request.prompt().getInstructions().stream()
                .map(this::redactMessage)
                .collect(Collectors.toList());
        
        Prompt newPrompt = new Prompt(
                redactedMessages,
                request.prompt().getOptions()
        );
        
        return request.updatePrompt(newPrompt);
    }
    
    @Override
    public ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context) {
        
        // Redact PII from AI responses
        List<Generation> redactedGenerations = response.getResults().stream()
                .map(this::redactGeneration)
                .collect(Collectors.toList());
        
        return new ChatResponse(redactedGenerations, response.getMetadata());
    }
    
    private Message redactMessage(Message message) {
        String redactedContent = redactPii(message.getContent());
        
        return switch (message.getMessageType()) {
            case USER -> new UserMessage(redactedContent);
            case ASSISTANT -> new AssistantMessage(redactedContent);
            case SYSTEM -> new SystemMessage(redactedContent);
            default -> message;
        };
    }
    
    private Generation redactGeneration(Generation generation) {
        AssistantMessage original = generation.getOutput();
        String redactedContent = redactPii(original.getContent());
        
        return new Generation(
                new AssistantMessage(redactedContent),
                generation.getMetadata()
        );
    }
    
    private String redactPii(String text) {
        String redacted = EMAIL_PATTERN.matcher(text).replaceAll("[EMAIL REDACTED]");
        redacted = PHONE_PATTERN.matcher(redacted).replaceAll("[PHONE REDACTED]");
        redacted = SSN_PATTERN.matcher(redacted).replaceAll("[SSN REDACTED]");
        return redacted;
    }
}
```

**Usage**:

```java
ChatClient client = ChatClient.builder(chatModel)
        .defaultAdvisors(new PiiRedactionAdvisor())
        .build();

String response = client.prompt()
        .user("My email is john@example.com and phone is 555-123-4567")
        .call()
        .content();

// Actual prompt sent to AI:
// "My email is [EMAIL REDACTED] and phone is [PHONE REDACTED]"
```

### Advisor Execution Order

Multiple advisors execute in order based on `getOrder()`:

```java
ChatClient client = ChatClient.builder(chatModel)
        .defaultAdvisors(
                new LoggingAdvisor(),           // order=0
                new PiiRedactionAdvisor(),      // order=1
                new MessageChatMemoryAdvisor(memory),  // order=2
                new QuestionAnswerAdvisor(vectorStore) // order=3
        )
        .build();
```

**Execution flow**:

```
BEFORE_CALL (ascending order):
1. LoggingAdvisor logs original request
2. PiiRedactionAdvisor redacts PII
3. MessageChatMemoryAdvisor adds history
4. QuestionAnswerAdvisor adds RAG context
   â†“
   ChatModel.call()
   â†“
AFTER_CALL (descending order):
4. QuestionAnswerAdvisor (no-op)
3. MessageChatMemoryAdvisor stores response
2. PiiRedactionAdvisor redacts response PII
1. LoggingAdvisor logs final response
```

ğŸ’¡ **Architecture Insight**: Advisors are the key to Spring AI's extensibility. You can add any cross-cutting concern (caching, translation, summarization, etc.) without modifying core code.

æ²¡ç»“æŸï¼æˆ‘æ‰å†™åˆ°å¤§çº¦40%çš„å†…å®¹ã€‚è®©æˆ‘ç»§ç»­å®Œæˆè¿™ç¯‡5000-6000å­—çš„æ·±åº¦æŒ‡å—ã€‚

---

## Model Abstractions

Let's dive deeper into how Spring AI abstracts different types of AI models.

### ChatModel Deep Dive

The `ChatModel` interface is the heart of Spring AI's chat functionality.

**Core Methods**:

```java
public interface ChatModel extends Model<Prompt, ChatResponse> {
    
    /**
     * Synchronous call - blocks until response received.
     * Use for simple requests or when you need the full response.
     */
    ChatResponse call(Prompt prompt);
    
    /**
     * Reactive streaming call - returns Flux for token-by-token streaming.
     * Use for long responses, better UX (progressive rendering).
     */
    Flux<ChatResponse> stream(Prompt prompt);
}
```

**Implementation Responsibilities**:

Every `ChatModel` implementation must:

1. **Convert Prompt to Provider Format**
```java
// Spring AI Prompt â†’ OpenAI API format
private ChatCompletionRequest createRequest(Prompt prompt) {
    return ChatCompletionRequest.builder()
            .model(getModel(prompt))
            .messages(toOpenAiMessages(prompt.getInstructions()))
            .temperature(getTemperature(prompt))
            .maxTokens(getMaxTokens(prompt))
            .build();
}
```

2. **Handle HTTP Communication**
```java
// Make actual API call
ChatCompletion completion = restClient.post()
        .uri("/v1/chat/completions")
        .body(request)
        .retrieve()
        .body(ChatCompletion.class);
```

3. **Convert Response to Spring AI Format**
```java
// OpenAI response â†’ Spring AI ChatResponse
private ChatResponse toChatResponse(ChatCompletion completion) {
    List<Generation> generations = completion.choices().stream()
            .map(choice -> new Generation(
                    new AssistantMessage(choice.message().content()),
                    toGenerationMetadata(choice)
            ))
            .toList();
    
    return new ChatResponse(
            generations,
            toChatResponseMetadata(completion)
    );
}
```

4. **Implement Streaming (Optional)**
```java
@Override
public Flux<ChatResponse> stream(Prompt prompt) {
    ChatCompletionRequest request = createRequest(prompt);
    
    // Server-Sent Events (SSE) stream
    return webClient.post()
            .uri("/v1/chat/completions")
            .bodyValue(request)
            .retrieve()
            .bodyToFlux(ChatCompletionChunk.class)
            .map(this::toStreamingChatResponse);
}
```

### EmbeddingModel Deep Dive

Embedding models convert text into vector representations.

```java
public interface EmbeddingModel extends Model<EmbeddingRequest, EmbeddingResponse> {
    
    /**
     * Generate embeddings for multiple texts.
     */
    EmbeddingResponse embedForResponse(List<String> texts);
    
    /**
     * Convenience method - just return vectors.
     */
    default List<float[]> embed(List<String> texts) {
        return embedForResponse(texts).getResults().stream()
                .map(Embedding::getOutput)
                .toList();
    }
    
    /**
     * Single text embedding (convenience).
     */
    default float[] embed(String text) {
        return embed(List.of(text)).get(0);
    }
    
    /**
     * Embed a document (uses document content).
     */
    default List<float[]> embed(List<Document> documents) {
        return embed(documents.stream()
                .map(Document::getContent)
                .toList());
    }
    
    /**
     * Get dimensions of embedding vectors.
     * Important for vector store configuration.
     */
    int dimensions();
}
```

**EmbeddingRequest/Response**:

```java
public class EmbeddingRequest {
    private List<String> inputs;         // Texts to embed
    private EmbeddingOptions options;    // Model, encoding format, etc.
}

public class EmbeddingResponse {
    private List<Embedding> results;     // One per input text
    private EmbeddingResponseMetadata metadata;
}

public class Embedding {
    private float[] embedding;           // The vector
    private Integer index;               // Position in batch
}
```

**Usage Example**:

```java
@Service
public class SemanticSearchService {
    
    private final EmbeddingModel embeddingModel;
    private final VectorStore vectorStore;
    
    public void indexDocuments(List<String> documents) {
        // 1. Generate embeddings
        List<float[]> embeddings = embeddingModel.embed(documents);
        
        // 2. Create Document objects with embeddings
        List<Document> docs = IntStream.range(0, documents.size())
                .mapToObj(i -> {
                    Document doc = new Document(documents.get(i));
                    doc.setEmbedding(embeddings.get(i));
                    return doc;
                })
                .toList();
        
        // 3. Store in vector database
        vectorStore.add(docs);
    }
    
    public List<String> search(String query, int topK) {
        // 1. Embed query
        float[] queryEmbedding = embeddingModel.embed(query);
        
        // 2. Search vector store
        List<Document> results = vectorStore.similaritySearch(
                SearchRequest.query(query)
                        .withTopK(topK)
                        .withSimilarityThreshold(0.7)
        );
        
        return results.stream()
                .map(Document::getContent)
                .toList();
    }
}
```

### ImageModel

For image generation (DALL-E, Stable Diffusion, etc.):

```java
public interface ImageModel extends Model<ImagePrompt, ImageResponse> {
    
    ImageResponse call(ImagePrompt request);
}

public class ImagePrompt {
    private String instructions;         // Text description
    private ImageOptions options;        // Size, quality, style
}

public class ImageResponse {
    private List<ImageGeneration> results;
    private ImageResponseMetadata metadata;
}

public class ImageGeneration {
    private Image image;                 // URL or base64 data
    private ImageGenerationMetadata metadata;
}
```

**Usage**:

```java
ImageModel imageModel = ...; // DALL-E, Stability AI, etc.

ImageResponse response = imageModel.call(
        new ImagePrompt(
                "A serene mountain landscape at sunset",
                ImageOptionsBuilder.builder()
                        .withModel("dall-e-3")
                        .withWidth(1024)
                        .withHeight(1024)
                        .withQuality("hd")
                        .build()
        )
);

String imageUrl = response.getResult().getOutput().getUrl();
```

### Multi-Modal Models

Modern models (GPT-4 Vision, Claude 3, Gemini) support images in prompts:

```java
// Spring AI supports multi-modal through Media objects
UserMessage message = new UserMessage(
        "What's in this image?",
        List.of(
                new Media(MimeTypeUtils.IMAGE_PNG, 
                         new ClassPathResource("photo.png"))
        )
);

ChatResponse response = chatModel.call(new Prompt(message));
```

### Model Capabilities

Different models have different capabilities. Spring AI provides metadata:

```java
public interface ModelCapabilities {
    
    /**
     * Does this model support streaming?
     */
    boolean supportsStreaming();
    
    /**
     * Does this model support function calling?
     */
    boolean supportsFunctionCalling();
    
    /**
     * Does this model support vision (image inputs)?
     */
    boolean supportsVision();
    
    /**
     * Maximum context window in tokens.
     */
    int maxContextLength();
    
    /**
     * Supported output formats.
     */
    List<String> supportedOutputFormats();
}
```

**Usage**:

```java
ChatModel chatModel = ...;

if (chatModel instanceof OpenAiChatModel openAi) {
    ModelCapabilities caps = openAi.getCapabilities();
    
    if (caps.supportsFunctionCalling()) {
        // Use function calling
    }
    
    if (caps.supportsVision()) {
        // Include images in prompts
    }
}
```

---

## Auto-Configuration Magic

Spring AI's auto-configuration makes setup effortless. Let's understand how it works.

### Auto-Configuration Classes

Each provider has an auto-configuration class:

```java
@AutoConfiguration
@ConditionalOnClass(OpenAiApi.class)
@EnableConfigurationProperties({
    OpenAiConnectionProperties.class,
    OpenAiChatProperties.class,
    OpenAiEmbeddingProperties.class
})
public class OpenAiAutoConfiguration {
    
    // ... beans defined here
}
```

**Key Annotations**:

- `@AutoConfiguration`: Marks this as a Spring Boot auto-config
- `@ConditionalOnClass`: Only activates if OpenAI classes are on classpath
- `@EnableConfigurationProperties`: Binds `application.yml` to Java objects

### Bean Creation Order

Auto-configuration creates beans in specific order:

```
1. RestClient.Builder (HTTP client configuration)
   â†“
2. OpenAiApi (API wrapper with HTTP client)
   â†“
3. OpenAiChatModel (ChatModel implementation)
   â†“
4. OpenAiEmbeddingModel (EmbeddingModel implementation)
   â†“
5. ChatClient.Builder (Fluent API builder)
```

**Example: OpenAI Auto-Configuration**

```java
@AutoConfiguration
public class OpenAiAutoConfiguration {
    
    /**
     * Step 1: Create HTTP client.
     */
    @Bean
    @ConditionalOnMissingBean
    public RestClient.Builder restClientBuilder() {
        return RestClient.builder()
                .requestInterceptor((request, body, execution) -> {
                    // Add logging, metrics, etc.
                    return execution.execute(request, body);
                });
    }
    
    /**
     * Step 2: Create OpenAI API wrapper.
     */
    @Bean
    @ConditionalOnMissingBean
    public OpenAiApi openAiApi(
            OpenAiConnectionProperties properties,
            RestClient.Builder restClientBuilder) {
        
        RestClient restClient = restClientBuilder
                .baseUrl(properties.getBaseUrl())
                .defaultHeader("Authorization", "Bearer " + properties.getApiKey())
                .build();
        
        return new OpenAiApi(restClient);
    }
    
    /**
     * Step 3: Create ChatModel.
     */
    @Bean
    @ConditionalOnMissingBean(ChatModel.class)
    public OpenAiChatModel openAiChatModel(
            OpenAiApi openAiApi,
            OpenAiChatProperties chatProperties,
            @Autowired(required = false) ObservationRegistry observationRegistry) {
        
        return new OpenAiChatModel(
                openAiApi,
                chatProperties.getOptions(),
                createRetryTemplate(chatProperties.getRetry()),
                observationRegistry != null ? observationRegistry : ObservationRegistry.NOOP
        );
    }
    
    /**
     * Step 4: Create EmbeddingModel.
     */
    @Bean
    @ConditionalOnMissingBean(EmbeddingModel.class)
    public OpenAiEmbeddingModel openAiEmbeddingModel(
            OpenAiApi openAiApi,
            OpenAiEmbeddingProperties embeddingProperties) {
        
        return new OpenAiEmbeddingModel(
                openAiApi,
                embeddingProperties.getMetadataMode(),
                embeddingProperties.getOptions(),
                createRetryTemplate(embeddingProperties.getRetry())
        );
    }
    
    /**
     * Step 5: Create ChatClient.Builder.
     */
    @Bean
    @ConditionalOnMissingBean
    public ChatClient.Builder chatClientBuilder(ChatModel chatModel) {
        return ChatClient.builder(chatModel);
    }
    
    private RetryTemplate createRetryTemplate(RetryProperties properties) {
        return RetryTemplate.builder()
                .maxAttempts(properties.getMaxAttempts())
                .exponentialBackoff(
                        properties.getBackoff().getInitialInterval(),
                        properties.getBackoff().getMultiplier(),
                        properties.getBackoff().getMaxInterval()
                )
                .retryOn(RetryableException.class)
                .build();
    }
}
```

### Property Binding

Configuration properties are bound to Java objects:

```java
@ConfigurationProperties("spring.ai.openai")
public class OpenAiConnectionProperties {
    
    /**
     * OpenAI API key.
     * Can be set via spring.ai.openai.api-key or SPRING_AI_OPENAI_API_KEY env var.
     */
    private String apiKey;
    
    /**
     * Base URL for OpenAI API.
     * Default: https://api.openai.com
     * Override for Azure OpenAI: https://{resource}.openai.azure.com
     */
    private String baseUrl = "https://api.openai.com";
    
    // Getters and setters...
}

@ConfigurationProperties("spring.ai.openai.chat")
public class OpenAiChatProperties {
    
    /**
     * Whether chat model is enabled.
     */
    private boolean enabled = true;
    
    /**
     * Default options for chat requests.
     */
    private ChatOptions options = ChatOptions.builder()
            .withModel("gpt-3.5-turbo")
            .withTemperature(0.7)
            .build();
    
    /**
     * Retry configuration.
     */
    private RetryProperties retry = new RetryProperties();
    
    public static class ChatOptions {
        private String model = "gpt-3.5-turbo";
        private Double temperature = 0.7;
        private Integer maxTokens;
        private Double topP;
        private List<String> stop;
        // ...
    }
    
    public static class RetryProperties {
        private int maxAttempts = 10;
        private BackoffProperties backoff = new BackoffProperties();
        
        public static class BackoffProperties {
            private Duration initialInterval = Duration.ofSeconds(2);
            private double multiplier = 5.0;
            private Duration maxInterval = Duration.ofMinutes(3);
        }
    }
}
```

**Application Configuration**:

```yaml
spring:
  ai:
    openai:
      # Connection settings
      api-key: ${OPENAI_API_KEY}
      base-url: https://api.openai.com
      
      # Chat model settings
      chat:
        enabled: true
        options:
          model: gpt-4o
          temperature: 0.7
          max-tokens: 2000
          top-p: 1.0
          frequency-penalty: 0.0
          presence-penalty: 0.0
        retry:
          max-attempts: 5
          backoff:
            initial-interval: 2s
            multiplier: 2
            max-interval: 10s
      
      # Embedding model settings
      embedding:
        enabled: true
        options:
          model: text-embedding-3-small
```

### Conditional Bean Creation

Spring AI uses Spring Boot's conditional annotations to avoid conflicts:

```java
@Bean
@ConditionalOnMissingBean(ChatModel.class)  // Only if no ChatModel exists
public OpenAiChatModel openAiChatModel(...) {
    return new OpenAiChatModel(...);
}
```

**Why this matters**:

If you have multiple AI providers on classpath:

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-anthropic-spring-boot-starter</artifactId>
    </dependency>
</dependencies>
```

Spring Boot will create both `OpenAiChatModel` and `AnthropicChatModel` beans. You can inject the specific one you need:

```java
@Service
public class MultiModelService {
    
    private final ChatModel openAiModel;
    private final ChatModel anthropicModel;
    
    public MultiModelService(
            @Qualifier("openAiChatModel") ChatModel openAiModel,
            @Qualifier("anthropicChatModel") ChatModel anthropicModel) {
        this.openAiModel = openAiModel;
        this.anthropicModel = anthropicModel;
    }
    
    public String compareModels(String prompt) {
        String openAiResponse = openAiModel.call(new Prompt(prompt))
                .getResult().getOutput().getContent();
        
        String anthropicResponse = anthropicModel.call(new Prompt(prompt))
                .getResult().getOutput().getContent();
        
        return "OpenAI: " + openAiResponse + "\n\nAnthropic: " + anthropicResponse;
    }
}
```

### Custom Configuration Override

You can override auto-configuration by defining your own beans:

```java
@Configuration
public class CustomChatConfig {
    
    /**
     * Custom ChatModel bean - auto-configuration will skip its bean.
     */
    @Bean
    public ChatModel chatModel(OpenAiApi openAiApi) {
        // Custom configuration
        return new OpenAiChatModel(
                openAiApi,
                ChatOptions.builder()
                        .withModel("gpt-4o")
                        .withTemperature(0.0)  // Deterministic
                        .withMaxTokens(500)
                        .build(),
                customRetryTemplate(),
                ObservationRegistry.create()
        );
    }
    
    private RetryTemplate customRetryTemplate() {
        return RetryTemplate.builder()
                .maxAttempts(3)
                .fixedBackoff(1000)  // 1 second between retries
                .retryOn(ApiException.class)
                .build();
    }
}
```

### Environment-Specific Configuration

Use Spring profiles for different environments:

```yaml
# application.yml (default)
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-3.5-turbo
          temperature: 0.7

---
# application-production.yml
spring:
  ai:
    openai:
      chat:
        options:
          model: gpt-4o  # Better model in production
          temperature: 0.3  # More consistent
        retry:
          max-attempts: 10  # More retries in production

---
# application-development.yml
spring:
  ai:
    openai:
      chat:
        options:
          model: gpt-3.5-turbo  # Cheaper for development
          max-tokens: 100  # Limit tokens during testing
```

Run with: `java -jar app.jar --spring.profiles.active=production`

---

## Metadata and Response Handling

Every AI interaction produces rich metadata. Let's understand how to use it.

### ChatResponse Structure

```java
public class ChatResponse implements ModelResponse<Generation> {
    
    private final List<Generation> results;
    private final ChatResponseMetadata metadata;
    
    /**
     * Get all generations (multiple if n > 1).
     */
    @Override
    public List<Generation> getResults() {
        return this.results;
    }
    
    /**
     * Convenience: get first generation.
     */
    public Generation getResult() {
        return this.results.get(0);
    }
    
    /**
     * Response-level metadata (usage, model, etc.).
     */
    @Override
    public ChatResponseMetadata getMetadata() {
        return this.metadata;
    }
}
```

### Generation

A single generated completion:

```java
public class Generation implements ModelResult<AssistantMessage> {
    
    private final AssistantMessage assistantMessage;
    private final ChatGenerationMetadata generationMetadata;
    
    @Override
    public AssistantMessage getOutput() {
        return this.assistantMessage;
    }
    
    @Override
    public ChatGenerationMetadata getMetadata() {
        return this.generationMetadata;
    }
}
```

### ChatResponseMetadata

Response-level metadata:

```java
public class ChatResponseMetadata {
    
    private String id;                    // Unique response ID
    private String model;                 // Model used (e.g., "gpt-4o")
    private Usage usage;                  // Token consumption
    private RateLimit rateLimit;          // Rate limit info
    private List<String> finishReasons;   // Why generation stopped
    
    /**
     * Token usage statistics.
     */
    public interface Usage {
        Long getPromptTokens();           // Tokens in prompt
        Long getGenerationTokens();       // Tokens in response
        Long getTotalTokens();            // Sum of above
    }
    
    /**
     * Rate limit information from provider.
     */
    public interface RateLimit {
        Long getRequestsLimit();          // Max requests per period
        Long getRequestsRemaining();      // Requests left
        Long getTokensLimit();            // Max tokens per period
        Long getTokensRemaining();        // Tokens left
        Duration getRequestsReset();      // When request limit resets
        Duration getTokensReset();        // When token limit resets
    }
}
```

### ChatGenerationMetadata

Per-generation metadata:

```java
public class ChatGenerationMetadata {
    
    private String finishReason;          // stop, length, content_filter, etc.
    private Map<String, Object> metadata; // Provider-specific data
    
    public String getFinishReason() {
        return this.finishReason;
    }
}
```

**Finish Reasons**:

- `stop`: Natural completion (hit stop sequence or model decided to stop)
- `length`: Max tokens reached
- `content_filter`: Content filtered by moderation
- `tool_calls`: Model wants to call a function
- `null`: Still generating (in streaming)

### Extracting Metadata

```java
ChatResponse response = chatClient.prompt()
        .user("Write a detailed essay about AI")
        .options(ChatOptionsBuilder.builder()
                .withMaxTokens(1000)
                .build())
        .call()
        .chatResponse();

// Response metadata
ChatResponseMetadata responseMeta = response.getMetadata();
System.out.println("Response ID: " + responseMeta.getId());
System.out.println("Model: " + responseMeta.getModel());

// Usage
Usage usage = responseMeta.getUsage();
System.out.println("Prompt tokens: " + usage.getPromptTokens());
System.out.println("Completion tokens: " + usage.getGenerationTokens());
System.out.println("Total tokens: " + usage.getTotalTokens());

// Calculate cost (example for GPT-4o)
double promptCost = usage.getPromptTokens() / 1000.0 * 0.005;   // $5 per 1M tokens
double completionCost = usage.getGenerationTokens() / 1000.0 * 0.015; // $15 per 1M tokens
double totalCost = promptCost + completionCost;
System.out.println("Cost: $" + String.format("%.6f", totalCost));

// Rate limits
RateLimit rateLimit = responseMeta.getRateLimit();
System.out.println("Requests remaining: " + rateLimit.getRequestsRemaining());
System.out.println("Tokens remaining: " + rateLimit.getTokensRemaining());
System.out.println("Rate limit resets in: " + rateLimit.getRequestsReset().getSeconds() + "s");

// Generation metadata
Generation generation = response.getResult();
ChatGenerationMetadata genMeta = generation.getMetadata();
System.out.println("Finish reason: " + genMeta.getFinishReason());

if ("length".equals(genMeta.getFinishReason())) {
    System.out.println("Warning: Response truncated due to max_tokens limit!");
}
```

### Usage Tracking Service

Build a service to track API usage:

```java
@Service
public class UsageTrackingService {
    
    private final AtomicLong totalPromptTokens = new AtomicLong(0);
    private final AtomicLong totalCompletionTokens = new AtomicLong(0);
    private final AtomicLong totalRequests = new AtomicLong(0);
    
    public void trackUsage(ChatResponse response) {
        Usage usage = response.getMetadata().getUsage();
        
        if (usage != null) {
            totalPromptTokens.addAndGet(usage.getPromptTokens());
            totalCompletionTokens.addAndGet(usage.getGenerationTokens());
            totalRequests.incrementAndGet();
        }
    }
    
    public UsageStats getStats() {
        return new UsageStats(
                totalRequests.get(),
                totalPromptTokens.get(),
                totalCompletionTokens.get(),
                totalPromptTokens.get() + totalCompletionTokens.get()
        );
    }
    
    public double estimateCost(String model) {
        // Pricing as of 2025 (example)
        return switch (model) {
            case "gpt-4o" -> 
                    (totalPromptTokens.get() / 1000.0 * 0.005) +
                    (totalCompletionTokens.get() / 1000.0 * 0.015);
            case "gpt-3.5-turbo" ->
                    (totalPromptTokens.get() / 1000.0 * 0.0005) +
                    (totalCompletionTokens.get() / 1000.0 * 0.0015);
            default -> 0.0;
        };
    }
    
    public record UsageStats(
            long requests,
            long promptTokens,
            long completionTokens,
            long totalTokens
    ) {}
}
```

Use with advisor:

```java
@Component
public class UsageTrackingAdvisor implements RequestResponseAdvisor {
    
    private final UsageTrackingService usageTracker;
    
    @Override
    public ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context) {
        
        usageTracker.trackUsage(response);
        return response;
    }
}
```

---

## Prompt Engineering Architecture

Spring AI provides powerful prompt engineering utilities.

### PromptTemplate

Dynamic prompt construction:

```java
public class PromptTemplate {
    
    private final String template;
    private final Map<String, Object> defaultModel;
    
    public PromptTemplate(String template) {
        this.template = template;
        this.defaultModel = new HashMap<>();
    }
    
    public PromptTemplate(String template, Map<String, Object> model) {
        this.template = template;
        this.defaultModel = model;
    }
    
    /**
     * Create prompt with placeholders filled.
     */
    public Prompt create(Map<String, Object> model) {
        Map<String, Object> mergedModel = new HashMap<>(defaultModel);
        mergedModel.putAll(model);
        
        String rendered = render(template, mergedModel);
        return new Prompt(rendered);
    }
}
```

**Usage**:

```java
PromptTemplate template = new PromptTemplate("""
        You are a {role}.
        Answer the following question about {topic}:
        
        {question}
        
        Provide a {style} answer.
        """);

Prompt prompt = template.create(Map.of(
        "role", "helpful teacher",
        "topic", "machine learning",
        "question", "What is gradient descent?",
        "style", "simple and concise"
));

String response = chatClient.prompt(prompt).call().content();
```

### Resource-Based Templates

Load templates from files:

```java
// src/main/resources/prompts/customer-support.st
You are a customer support agent for {company}.

Customer query: {query}

Previous conversation:
{history}

Respond professionally and helpfully.
```

```java
@Service
public class CustomerSupportService {
    
    @Value("classpath:/prompts/customer-support.st")
    private Resource templateResource;
    
    public String handleQuery(String query, String history) {
        PromptTemplate template = new PromptTemplate(templateResource);
        
        Prompt prompt = template.create(Map.of(
                "company", "Acme Corp",
                "query", query,
                "history", history
        ));
        
        return chatClient.prompt(prompt).call().content();
    }
}
```

### System Message Templates

```java
@Configuration
public class PromptConfig {
    
    @Bean
    public ChatClient customerSupportClient(ChatModel chatModel) {
        
        String systemTemplate = """
                You are a customer support agent for {company}.
                Your tone should be {tone}.
                Your responses should be {length}.
                """;
        
        PromptTemplate template = new PromptTemplate(systemTemplate);
        String systemMessage = template.create(Map.of(
                "company", "Acme Corp",
                "tone", "friendly and professional",
                "length", "concise but complete"
        )).getContents();
        
        return ChatClient.builder(chatModel)
                .defaultSystem(systemMessage)
                .build();
    }
}
```

### Few-Shot Prompting

Provide examples to guide the model:

```java
public class FewShotPromptBuilder {
    
    private final List<Message> examples = new ArrayList<>();
    private String systemInstruction;
    
    public FewShotPromptBuilder withSystem(String instruction) {
        this.systemInstruction = instruction;
        return this;
    }
    
    public FewShotPromptBuilder addExample(String input, String output) {
        examples.add(new UserMessage(input));
        examples.add(new AssistantMessage(output));
        return this;
    }
    
    public Prompt build(String actualInput) {
        List<Message> messages = new ArrayList<>();
        
        if (systemInstruction != null) {
            messages.add(new SystemMessage(systemInstruction));
        }
        
        messages.addAll(examples);
        messages.add(new UserMessage(actualInput));
        
        return new Prompt(messages);
    }
}
```

**Usage - Sentiment Classification**:

```java
FewShotPromptBuilder builder = new FewShotPromptBuilder()
        .withSystem("Classify the sentiment of the text as positive, negative, or neutral.")
        .addExample("I love this product!", "positive")
        .addExample("This is terrible.", "negative")
        .addExample("It's okay, nothing special.", "neutral");

Prompt prompt = builder.build("This exceeded my expectations!");

String sentiment = chatClient.prompt(prompt).call().content();
// Output: "positive"
```

### Structured Prompting

Extract structured data:

```java
public record ProductReview(
        String product,
        int rating,
        String sentiment,
        List<String> pros,
        List<String> cons
) {}

String reviewText = """
        I bought the XPhone Pro and it's amazing! The camera quality is outstanding
        and battery lasts all day. However, it's quite expensive and a bit heavy.
        Overall, I'd rate it 4 out of 5 stars.
        """;

PromptTemplate template = new PromptTemplate("""
        Extract structured information from this product review:
        
        {review}
        
        Return a JSON object with: product, rating (1-5), sentiment (positive/negative/neutral),
        pros (array), cons (array).
        """);

Prompt prompt = template.create(Map.of("review", reviewText));

ProductReview review = chatClient.prompt(prompt)
        .call()
        .entity(ProductReview.class);

System.out.println("Product: " + review.product());
System.out.println("Rating: " + review.rating());
System.out.println("Pros: " + String.join(", ", review.pros()));
```

---

è®©æˆ‘ç»§ç»­å®Œæˆå‰©ä½™çš„ç« èŠ‚...

## Vector Store Architecture

Vector stores are critical for RAG (Retrieval-Augmented Generation) architectures.

### VectorStore Interface

```java
public interface VectorStore {
    
    /**
     * Add documents to the vector store.
     * Documents are automatically embedded using configured EmbeddingModel.
     */
    void add(List<Document> documents);
    
    /**
     * Delete documents by IDs.
     */
    Optional<Boolean> delete(List<String> idList);
    
    /**
     * Similarity search - find similar documents.
     */
    List<Document> similaritySearch(SearchRequest request);
    
    /**
     * Similarity search with scores.
     */
    List<Document> similaritySearch(String query);
    
    /**
     * Optional: Get document by ID.
     */
    default Optional<Document> get(String id) {
        throw new UnsupportedOperationException("get() not supported");
    }
}
```

### SearchRequest

```java
public class SearchRequest {
    
    private String query;                    // Search query
    private int topK = 4;                    // Number of results
    private double similarityThreshold = 0.0; // Minimum similarity (0.0-1.0)
    private FilterExpression filterExpression; // Metadata filtering
    
    public static SearchRequest query(String query) {
        return new SearchRequest(query);
    }
    
    public static SearchRequest defaults() {
        return new SearchRequest("");
    }
    
    public SearchRequest withTopK(int topK) {
        this.topK = topK;
        return this;
    }
    
    public SearchRequest withSimilarityThreshold(double threshold) {
        this.similarityThreshold = threshold;
        return this;
    }
    
    public SearchRequest withFilterExpression(FilterExpression filter) {
        this.filterExpression = filter;
        return this;
    }
}
```

### Document Structure

```java
public class Document {
    
    private String id;                       // Unique identifier
    private String content;                  // Text content
    private Map<String, Object> metadata;    // Arbitrary metadata
    private float[] embedding;               // Vector representation
    private Double score;                    // Similarity score (after search)
    
    public Document(String content) {
        this(UUID.randomUUID().toString(), content, new HashMap<>());
    }
    
    public Document(String id, String content, Map<String, Object> metadata) {
        this.id = id;
        this.content = content;
        this.metadata = metadata;
    }
    
    // Convenience methods for metadata
    public Document withMetadata(String key, Object value) {
        this.metadata.put(key, value);
        return this;
    }
    
    public <T> T getMetadata(String key) {
        return (T) this.metadata.get(key);
    }
}
```

### Vector Store Implementations

Spring AI supports multiple vector stores:

**1. PostgreSQL with pgvector**:

```java
@Configuration
public class VectorStoreConfig {
    
    @Bean
    public VectorStore pgVectorStore(
            JdbcTemplate jdbcTemplate,
            EmbeddingModel embeddingModel) {
        
        return new PgVectorStore(jdbcTemplate, embeddingModel);
    }
}
```

```yaml
spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/vectordb
    username: postgres
    password: postgres
  ai:
    vectorstore:
      pgvector:
        index-type: HNSW  # or IVFFlat
        distance-type: COSINE_DISTANCE  # or EUCLIDEAN_DISTANCE
        dimensions: 1536  # For OpenAI embeddings
```

**2. Redis**:

```java
@Bean
public VectorStore redisVectorStore(
        RedisVectorStoreConfig config,
        EmbeddingModel embeddingModel) {
    
    return new RedisVectorStore(config, embeddingModel);
}
```

**3. ChromaDB**:

```java
@Bean
public VectorStore chromaVectorStore(EmbeddingModel embeddingModel) {
    return new ChromaVectorStore(
            ChromaApi.create("http://localhost:8000"),
            embeddingModel
    );
}
```

### Using Vector Stores

**Basic RAG Pipeline**:

```java
@Service
public class DocumentSearchService {
    
    private final VectorStore vectorStore;
    private final EmbeddingModel embeddingModel;
    private final ChatClient chatClient;
    
    /**
     * Index documents for retrieval.
     */
    public void indexDocuments(List<String> documentTexts) {
        List<Document> documents = documentTexts.stream()
                .map(text -> new Document(text)
                        .withMetadata("indexed_at", Instant.now())
                        .withMetadata("source", "user_upload"))
                .toList();
        
        vectorStore.add(documents);
    }
    
    /**
     * Search with metadata filtering.
     */
    public List<Document> searchRecent(String query, int days) {
        Instant cutoff = Instant.now().minus(Duration.ofDays(days));
        
        FilterExpression filter = new Filter.Expression(
                Filter.ExpressionType.GTE,
                new Filter.Key("indexed_at"),
                new Filter.Value(cutoff)
        );
        
        return vectorStore.similaritySearch(
                SearchRequest.query(query)
                        .withTopK(5)
                        .withSimilarityThreshold(0.7)
                        .withFilterExpression(filter)
        );
    }
    
    /**
     * RAG: Retrieval-Augmented Generation.
     */
    public String answerQuestion(String question) {
        // 1. Retrieve relevant documents
        List<Document> relevantDocs = vectorStore.similaritySearch(
                SearchRequest.query(question)
                        .withTopK(3)
                        .withSimilarityThreshold(0.75)
        );
        
        // 2. Build context from documents
        String context = relevantDocs.stream()
                .map(doc -> {
                    String source = doc.getMetadata("source");
                    return String.format("[Source: %s]\n%s", source, doc.getContent());
                })
                .collect(Collectors.joining("\n\n---\n\n"));
        
        // 3. Generate answer with context
        String prompt = String.format("""
                Based on the following context, answer the question.
                If the answer is not in the context, say "I don't know."
                
                Context:
                %s
                
                Question: %s
                
                Answer:
                """, context, question);
        
        return chatClient.prompt(prompt).call().content();
    }
}
```

### Advanced: Hybrid Search

Combine vector similarity with keyword search:

```java
@Service
public class HybridSearchService {
    
    private final VectorStore vectorStore;
    private final FullTextSearchRepository fullTextRepo;
    
    public List<Document> hybridSearch(String query, int topK) {
        // 1. Vector similarity search
        List<Document> vectorResults = vectorStore.similaritySearch(
                SearchRequest.query(query).withTopK(topK * 2)
        );
        
        // 2. Keyword/BM25 search
        List<Document> keywordResults = fullTextRepo.search(query, topK * 2);
        
        // 3. Reciprocal Rank Fusion (RRF)
        Map<String, Double> scores = new HashMap<>();
        
        for (int i = 0; i < vectorResults.size(); i++) {
            String id = vectorResults.get(i).getId();
            scores.merge(id, 1.0 / (60 + i + 1), Double::sum);
        }
        
        for (int i = 0; i < keywordResults.size(); i++) {
            String id = keywordResults.get(i).getId();
            scores.merge(id, 1.0 / (60 + i + 1), Double::sum);
        }
        
        // 4. Re-rank and return top K
        return scores.entrySet().stream()
                .sorted(Map.Entry.<String, Double>comparingByValue().reversed())
                .limit(topK)
                .map(entry -> findDocumentById(entry.getKey(), vectorResults, keywordResults))
                .filter(Optional::isPresent)
                .map(Optional::get)
                .toList();
    }
}
```

---

## Document Processing Pipeline

Spring AI provides document readers for various formats.

### Document Readers

```java
public interface DocumentReader {
    /**
     * Read and parse document into Document objects.
     */
    List<Document> get();
}
```

### PDF Document Reader

```java
@Service
public class PdfIngestionService {
    
    private final VectorStore vectorStore;
    
    public void ingestPdf(Resource pdfResource) {
        // 1. Read PDF
        PagePdfDocumentReader pdfReader = new PagePdfDocumentReader(
                pdfResource,
                PdfDocumentReaderConfig.builder()
                        .withPageTopMargin(0)
                        .withPageBottomMargin(0)
                        .withPageExtractedTextFormatter(
                                ExtractedTextFormatter.builder()
                                        .withNumberOfTopTextLinesToDelete(0)
                                        .build()
                        )
                        .build()
        );
        
        List<Document> documents = pdfReader.get();
        
        // 2. Add metadata
        documents.forEach(doc -> {
            doc.getMetadata().put("source", pdfResource.getFilename());
            doc.getMetadata().put("type", "pdf");
            doc.getMetadata().put("ingested_at", Instant.now());
        });
        
        // 3. Split into chunks
        TokenTextSplitter splitter = new TokenTextSplitter();
        List<Document> chunks = splitter.apply(documents);
        
        // 4. Store in vector database
        vectorStore.add(chunks);
    }
}
```

### Text Splitters

Break documents into manageable chunks:

```java
/**
 * Split by character count.
 */
TextSplitter characterSplitter = new TokenTextSplitter(
        500,   // chunk size
        100    // overlap
);

/**
 * Split by token count (respects token limits).
 */
TokenTextSplitter tokenSplitter = new TokenTextSplitter(
        1000,  // max tokens per chunk
        200    // overlap in tokens
);

/**
 * Recursive text splitter - tries to split on paragraphs, then sentences.
 */
TextSplitter recursiveSplitter = new RecursiveCharacterTextSplitter(
        1000,
        200,
        List.of("\n\n", "\n", ". ", " ")  // Split delimiters in priority order
);
```

**Usage**:

```java
Document longDocument = new Document(veryLongText);

List<Document> chunks = tokenSplitter.apply(List.of(longDocument));

// Each chunk has metadata about position
chunks.forEach(chunk -> {
    System.out.println("Chunk ID: " + chunk.getId());
    System.out.println("Parent ID: " + chunk.getMetadata("parent_id"));
    System.out.println("Index: " + chunk.getMetadata("index"));
});
```

### Tika Document Reader

Read various formats (Word, Excel, HTML, etc.):

```java
@Service
public class MultiFormatIngestionService {
    
    private final VectorStore vectorStore;
    
    public void ingestDocument(Resource resource) {
        // Tika auto-detects format and extracts text
        TikaDocumentReader reader = new TikaDocumentReader(resource);
        
        List<Document> documents = reader.get();
        
        // Enrich with metadata
        documents.forEach(doc -> {
            doc.getMetadata().put("filename", resource.getFilename());
            doc.getMetadata().put("content_type", 
                    doc.getMetadata().getOrDefault("Content-Type", "unknown"));
        });
        
        // Split and store
        TextSplitter splitter = new TokenTextSplitter(800, 100);
        List<Document> chunks = splitter.apply(documents);
        
        vectorStore.add(chunks);
    }
}
```

### Complete Document Processing Pipeline

```java
@Service
public class DocumentProcessingPipeline {
    
    private final VectorStore vectorStore;
    private final EmbeddingModel embeddingModel;
    
    public void processDocument(
            Resource resource,
            Map<String, Object> customMetadata) {
        
        // 1. Read document
        List<Document> documents = readDocument(resource);
        
        // 2. Clean text
        documents = documents.stream()
                .map(this::cleanDocument)
                .toList();
        
        // 3. Add metadata
        documents.forEach(doc -> 
                doc.getMetadata().putAll(customMetadata));
        
        // 4. Split into chunks
        TextSplitter splitter = new TokenTextSplitter(1000, 200);
        List<Document> chunks = splitter.apply(documents);
        
        // 5. Generate embeddings (happens automatically in vectorStore.add())
        vectorStore.add(chunks);
        
        log.info("Processed {} chunks from {}", 
                chunks.size(), resource.getFilename());
    }
    
    private List<Document> readDocument(Resource resource) {
        String filename = resource.getFilename();
        
        if (filename.endsWith(".pdf")) {
            return new PagePdfDocumentReader(resource).get();
        } else if (filename.endsWith(".txt")) {
            return new TextDocumentReader(resource).get();
        } else {
            return new TikaDocumentReader(resource).get();
        }
    }
    
    private Document cleanDocument(Document doc) {
        String cleaned = doc.getContent()
                .replaceAll("\\s+", " ")      // Normalize whitespace
                .replaceAll("[\\x00-\\x1F]", "") // Remove control characters
                .trim();
        
        return new Document(doc.getId(), cleaned, doc.getMetadata());
    }
}
```

---

## Streaming and Reactive Support

Spring AI supports reactive streaming for real-time responses.

### Streaming API

```java
// Blocking (waits for full response)
String response = chatClient.prompt()
        .user("Write a long story")
        .call()
        .content();

// Streaming (receives chunks as they're generated)
Flux<String> stream = chatClient.prompt()
        .user("Write a long story")
        .stream()
        .content();

stream.subscribe(chunk -> System.out.print(chunk));
```

### Stream Response Spec

```java
public interface StreamResponseSpec {
    
    /**
     * Stream complete ChatResponse objects.
     */
    Flux<ChatResponse> chatResponse();
    
    /**
     * Stream just content strings.
     */
    Flux<String> content();
    
    /**
     * Stream structured entities.
     */
    <T> Flux<T> entity(Class<T> entityClass);
}
```

### Server-Sent Events (SSE) Controller

Stream responses to web clients:

```java
@RestController
@RequestMapping("/api/chat")
public class StreamingChatController {
    
    private final ChatClient chatClient;
    
    @GetMapping(value = "/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<ServerSentEvent<String>> streamChat(
            @RequestParam String message) {
        
        return chatClient.prompt()
                .user(message)
                .stream()
                .content()
                .map(chunk -> ServerSentEvent.<String>builder()
                        .data(chunk)
                        .build());
    }
    
    @GetMapping(value = "/stream-json", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<ServerSentEvent<ChatChunk>> streamChatJson(
            @RequestParam String message) {
        
        return chatClient.prompt()
                .user(message)
                .stream()
                .chatResponse()
                .map(response -> {
                    String content = response.getResult()
                            .getOutput()
                            .getContent();
                    
                    return ServerSentEvent.<ChatChunk>builder()
                            .data(new ChatChunk(content, false))
                            .build();
                })
                .concatWith(Mono.just(
                        ServerSentEvent.<ChatChunk>builder()
                                .data(new ChatChunk("", true))
                                .build()
                ));
    }
    
    record ChatChunk(String content, boolean done) {}
}
```

**Frontend (JavaScript)**:

```javascript
const eventSource = new EventSource('/api/chat/stream?message=Hello');

eventSource.onmessage = (event) => {
    const chunk = event.data;
    document.getElementById('response').innerHTML += chunk;
};

eventSource.onerror = () => {
    eventSource.close();
};
```

### Reactive Operators

Combine with Project Reactor operators:

```java
@Service
public class ReactiveConversationService {
    
    private final ChatClient chatClient;
    
    /**
     * Stream multiple questions in parallel.
     */
    public Flux<AnswerPair> streamMultipleQuestions(List<String> questions) {
        return Flux.fromIterable(questions)
                .flatMap(question -> 
                        chatClient.prompt()
                                .user(question)
                                .stream()
                                .content()
                                .reduce("", String::concat)
                                .map(answer -> new AnswerPair(question, answer))
                );
    }
    
    /**
     * Stream with timeout.
     */
    public Flux<String> streamWithTimeout(String query, Duration timeout) {
        return chatClient.prompt()
                .user(query)
                .stream()
                .content()
                .timeout(timeout, Flux.just("[Response timeout]"));
    }
    
    /**
     * Buffer chunks for smoother UI updates.
     */
    public Flux<String> streamBuffered(String query) {
        return chatClient.prompt()
                .user(query)
                .stream()
                .content()
                .bufferTimeout(10, Duration.ofMillis(100))
                .map(chunks -> String.join("", chunks));
    }
    
    record AnswerPair(String question, String answer) {}
}
```

---

## Function Calling Architecture

Function calling allows AI models to invoke your Java methods.

### Function Callback

```java
public interface FunctionCallback {
    
    /**
     * Name of the function (exposed to AI).
     */
    String getName();
    
    /**
     * Description of what the function does.
     */
    String getDescription();
    
    /**
     * JSON schema for function parameters.
     */
    String getInputTypeSchema();
    
    /**
     * Execute the function.
     */
    String call(String functionArguments);
}
```

### Defining Functions

**Method 1: Bean with @Description**:

```java
@Component
public class WeatherFunctions {
    
    @Bean
    @Description("Get current weather for a location")
    public Function<WeatherRequest, WeatherResponse> currentWeather() {
        return request -> {
            // Call actual weather API
            return new WeatherResponse(
                    request.location(),
                    72,
                    "sunny",
                    "clear skies"
            );
        };
    }
    
    record WeatherRequest(String location, String unit) {}
    record WeatherResponse(String location, int temperature, 
                          String condition, String description) {}
}
```

**Method 2: Manual FunctionCallback**:

```java
FunctionCallback calculator = FunctionCallback.builder()
        .name("calculate")
        .description("Perform mathematical calculations")
        .inputType(CalculationRequest.class)
        .function(request -> {
            double result = switch (request.operation()) {
                case "add" -> request.a() + request.b();
                case "subtract" -> request.a() - request.b();
                case "multiply" -> request.a() * request.b();
                case "divide" -> request.a() / request.b();
                default -> throw new IllegalArgumentException("Unknown operation");
            };
            return new CalculationResult(result);
        })
        .build();

record CalculationRequest(String operation, double a, double b) {}
record CalculationResult(double result) {}
```

### Using Functions

```java
@Service
public class FunctionCallingService {
    
    private final ChatClient chatClient;
    
    public String askWithFunctions(String question) {
        return chatClient.prompt()
                .user(question)
                .functions("currentWeather", "calculate")  // Enable functions
                .call()
                .content();
    }
}
```

**Example conversation**:

```
User: "What's the weather in Paris?"

[Behind the scenes]
1. AI decides to call currentWeather function
2. Spring AI calls: currentWeather({"location": "Paris", "unit": "celsius"})
3. Function returns: {"location": "Paris", "temperature": 22, "condition": "partly cloudy"}
4. AI receives function result
5. AI generates natural response: "The weather in Paris is partly cloudy with a temperature of 22Â°C."
```

### Function Calling Flow

```java
// Internal flow when AI wants to call a function:

class OpenAiChatModel {
    
    @Override
    public ChatResponse call(Prompt prompt) {
        
        // 1. Send request with available functions
        ChatCompletionRequest request = buildRequest(prompt);
        
        // 2. Get response - might contain tool_calls
        ChatCompletion completion = api.chatCompletion(request);
        
        // 3. Check if AI wants to call functions
        if (completion.hasToolCalls()) {
            
            // 4. Execute function calls
            List<FunctionResult> results = new ArrayList<>();
            
            for (ToolCall toolCall : completion.getToolCalls()) {
                FunctionCallback function = findFunction(toolCall.getName());
                String result = function.call(toolCall.getArguments());
                results.add(new FunctionResult(toolCall.getId(), result));
            }
            
            // 5. Send function results back to AI
            ChatCompletionRequest followUp = buildFollowUpRequest(
                    prompt,
                    completion,
                    results
            );
            
            // 6. Get final response
            completion = api.chatCompletion(followUp);
        }
        
        return toChatResponse(completion);
    }
}
```

### Complex Function Example

Multi-step workflow with functions:

```java
@Component
public class TravelAssistant {
    
    @Bean
    @Description("Search for flights between cities")
    public Function<FlightSearchRequest, List<Flight>> searchFlights() {
        return request -> flightService.search(
                request.origin(),
                request.destination(),
                request.date()
        );
    }
    
    @Bean
    @Description("Book a flight")
    public Function<FlightBookingRequest, BookingConfirmation> bookFlight() {
        return request -> flightService.book(
                request.flightId(),
                request.passengerName(),
                request.email()
        );
    }
    
    @Bean
    @Description("Get weather forecast for a destination")
    public Function<WeatherRequest, WeatherForecast> getWeatherForecast() {
        return request -> weatherService.getForecast(
                request.location(),
                request.days()
        );
    }
}
```

**Complex query**:

```
User: "I need to fly from NYC to Paris next Friday. Book the cheapest flight 
       and tell me what the weather will be like."

[AI orchestrates multiple function calls]
1. searchFlights({origin: "NYC", destination: "Paris", date: "2025-11-28"})
2. bookFlight({flightId: "AF123", passengerName: "...", email: "..."})
3. getWeatherForecast({location: "Paris", days: 7})

AI Response: "I've booked you on Air France flight AF123 departing NYC at 8:00 PM 
              next Friday, arriving in Paris at 9:30 AM. The flight costs $650. 
              The weather in Paris next week will be partly cloudy with temperatures 
              around 15-20Â°C."
```

---

## Structured Output Handling

Extract structured data from AI responses.

### Entity Mapping

```java
// Define your data structure
record Product(
        String name,
        String category,
        double price,
        List<String> features,
        Rating rating
) {}

record Rating(int stars, int reviewCount) {}

// Extract structured data
Product product = chatClient.prompt()
        .user("Tell me about the iPhone 15 Pro")
        .call()
        .entity(Product.class);

System.out.println("Product: " + product.name());
System.out.println("Price: $" + product.price());
System.out.println("Features: " + String.join(", ", product.features()));
```

### How It Works

Spring AI uses **JSON Mode** or **Structured Output** APIs:

```java
class DefaultCallResponseSpec {
    
    public <T> T entity(Class<T> entityClass) {
        
        // 1. Generate JSON schema from class
        String jsonSchema = generateJsonSchema(entityClass);
        
        // 2. Add schema to system prompt
        String systemPrompt = """
                Extract information and return ONLY a JSON object matching this schema:
                %s
                
                Do not include any explanatory text.
                """.formatted(jsonSchema);
        
        // 3. Request with JSON mode enabled
        ChatOptions options = ChatOptions.builder()
                .withResponseFormat(ResponseFormat.JSON)
                .build();
        
        String jsonResponse = chatClient.prompt()
                .system(systemPrompt)
                .user(originalUserMessage)
                .options(options)
                .call()
                .content();
        
        // 4. Deserialize JSON to Java object
        return objectMapper.readValue(jsonResponse, entityClass);
    }
}
```

### BeanOutputConverter

More control over conversion:

```java
BeanOutputConverter<Product> converter = 
        new BeanOutputConverter<>(Product.class);

String prompt = """
        Extract product information from this description:
        
        {description}
        
        {format}
        """;

PromptTemplate template = new PromptTemplate(prompt, Map.of(
        "description", productDescription,
        "format", converter.getFormat()  // Adds JSON schema instructions
));

Product product = converter.convert(
        chatClient.prompt(template.create())
                .call()
                .content()
);
```

### List of Entities

Extract multiple items:

```java
record Task(String title, String priority, LocalDate dueDate) {}

String tasks = chatClient.prompt()
        .user("""
                Parse these tasks:
                - Finish report by Friday (high priority)
                - Call dentist tomorrow (medium priority)
                - Buy groceries this weekend (low priority)
                """)
        .call()
        .content();

List<Task> taskList = objectMapper.readValue(
        tasks,
        new TypeReference<List<Task>>() {}
);
```

Or use `entity()` with `ParameterizedTypeReference`:

```java
List<Task> tasks = chatClient.prompt()
        .user("Parse these tasks: ...")
        .call()
        .entity(new ParameterizedTypeReference<List<Task>>() {});
```

### Validation

Validate extracted entities:

```java
record UserProfile(
        @NotBlank String name,
        @Email String email,
        @Min(18) int age,
        @Pattern(regexp = "\\d{3}-\\d{3}-\\d{4}") String phone
) {}

UserProfile profile = chatClient.prompt()
        .user("Extract user info: John Doe, john@example.com, 25, 555-123-4567")
        .call()
        .entity(UserProfile.class);

// Validate
ValidatorFactory factory = Validation.buildDefaultValidatorFactory();
Validator validator = factory.getValidator();
Set<ConstraintViolation<UserProfile>> violations = validator.validate(profile);

if (!violations.isEmpty()) {
    violations.forEach(v -> 
            System.out.println(v.getPropertyPath() + ": " + v.getMessage())
    );
}
```

---

## Error Handling and Resilience

Spring AI includes built-in error handling and resilience patterns.

### Exception Hierarchy

```java
// Base exception
public class SpringAiException extends RuntimeException {}

// API errors
public class ApiException extends SpringAiException {
    private final int statusCode;
    private final String errorCode;
}

// Rate limiting
public class RateLimitException extends ApiException {}

// Retryable errors
public class RetryableException extends ApiException {}

// Model errors
public class ModelException extends SpringAiException {}
```

### Retry Configuration

Configured per provider:

```yaml
spring:
  ai:
    openai:
      chat:
        retry:
          max-attempts: 10
          backoff:
            initial-interval: 2s
            multiplier: 5
            max-interval: 3m
          retryable-exceptions:
            - org.springframework.ai.retry.RetryableException
            - org.springframework.web.client.HttpServerErrorException
```

**Custom Retry Template**:

```java
@Bean
public ChatModel customRetryChatModel(OpenAiApi api) {
    RetryTemplate retryTemplate = RetryTemplate.builder()
            .maxAttempts(5)
            .exponentialBackoff(1000, 2, 10000)
            .retryOn(RateLimitException.class)
            .retryOn(RetryableException.class)
            .withListener(new RetryListenerSupport() {
                @Override
                public <T, E extends Throwable> void onError(
                        RetryContext context,
                        RetryCallback<T, E> callback,
                        Throwable throwable) {
                    
                    log.warn("Retry attempt {} failed: {}",
                            context.getRetryCount(),
                            throwable.getMessage());
                }
            })
            .build();
    
    return new OpenAiChatModel(api, options, retryTemplate, registry);
}
```

### Circuit Breaker

Use Resilience4j circuit breaker:

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-circuitbreaker-resilience4j</artifactId>
</dependency>
```

```java
@Service
public class ResilientChatService {
    
    private final ChatClient chatClient;
    private final CircuitBreakerFactory circuitBreakerFactory;
    
    public String chatWithCircuitBreaker(String message) {
        CircuitBreaker circuitBreaker = circuitBreakerFactory.create("chat");
        
        return circuitBreaker.run(
                () -> chatClient.prompt(message).call().content(),
                throwable -> "Service temporarily unavailable. Please try again later."
        );
    }
}
```

**Configuration**:

```yaml
resilience4j:
  circuitbreaker:
    instances:
      chat:
        sliding-window-size: 10
        failure-rate-threshold: 50
        wait-duration-in-open-state: 30s
        permitted-number-of-calls-in-half-open-state: 3
```

### Fallback Strategies

Multiple fallback levels:

```java
@Service
public class FallbackChatService {
    
    private final ChatModel primaryModel;    // GPT-4o
    private final ChatModel fallbackModel;   // GPT-3.5-turbo
    private final ChatModel localModel;      // Ollama (local)
    
    public String chat(String message) {
        try {
            return primaryModel.call(new Prompt(message))
                    .getResult().getOutput().getContent();
                    
        } catch (Exception e) {
            log.warn("Primary model failed, trying fallback: {}", e.getMessage());
            
            try {
                return fallbackModel.call(new Prompt(message))
                        .getResult().getOutput().getContent();
                        
            } catch (Exception e2) {
                log.warn("Fallback model failed, using local model: {}", e2.getMessage());
                
                return localModel.call(new Prompt(message))
                        .getResult().getOutput().getContent();
            }
        }
    }
}
```

### Rate Limit Handling

Respect rate limits:

```java
@Component
public class RateLimitingAdvisor implements RequestResponseAdvisor {
    
    private final RateLimiter rateLimiter;
    
    public RateLimitingAdvisor() {
        this.rateLimiter = RateLimiter.create(10.0);  // 10 requests/second
    }
    
    @Override
    public AdvisedRequest adviseRequest(
            AdvisedRequest request,
            Map<String, Object> context) {
        
        // Wait for rate limiter permit
        rateLimiter.acquire();
        
        return request;
    }
    
    @Override
    public ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context) {
        
        // Check rate limit from response
        RateLimit rateLimit = response.getMetadata().getRateLimit();
        
        if (rateLimit != null && rateLimit.getRequestsRemaining() < 10) {
            log.warn("Rate limit low: {} requests remaining",
                    rateLimit.getRequestsRemaining());
        }
        
        return response;
    }
}
```

---

## Observability Architecture

Spring AI provides comprehensive observability out-of-the-box.

### Metrics

Spring AI automatically records:

- **Request count**: Total API calls
- **Token usage**: Prompt tokens, completion tokens
- **Latency**: Request duration
- **Error rate**: Failed requests

**Enable metrics**:

```yaml
management:
  metrics:
    export:
      prometheus:
        enabled: true
  endpoints:
    web:
      exposure:
        include: health,metrics,prometheus
```

**Available metrics**:

```
# Request count by model and operation
spring_ai_chat_client_requests_total{model="gpt-4o",operation="call"} 42

# Token usage
spring_ai_chat_client_tokens_total{model="gpt-4o",type="prompt"} 15420
spring_ai_chat_client_tokens_total{model="gpt-4o",type="completion"} 8765

# Request duration
spring_ai_chat_client_request_duration_seconds{model="gpt-4o",quantile="0.5"} 1.2
spring_ai_chat_client_request_duration_seconds{model="gpt-4o",quantile="0.95"} 3.5

# Error rate
spring_ai_chat_client_errors_total{model="gpt-4o",error_type="rate_limit"} 3
```

### Distributed Tracing

Spring AI integrates with Micrometer Tracing:

```xml
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-brave</artifactId>
</dependency>
<dependency>
    <groupId>io.zipkin.reporter2</groupId>
    <artifactId>zipkin-reporter-brave</artifactId>
</dependency>
```

```yaml
management:
  tracing:
    sampling:
      probability: 1.0  # 100% sampling for development
  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans
```

**Trace structure**:

```
Span: ChatClient.call()
  â”œâ”€ Span: Advisor.beforeCall (MessageChatMemoryAdvisor)
  â”œâ”€ Span: Advisor.beforeCall (QuestionAnswerAdvisor)
  â”‚   â””â”€ Span: VectorStore.similaritySearch
  â”‚       â””â”€ Span: EmbeddingModel.embed
  â”œâ”€ Span: ChatModel.call (OpenAiChatModel)
  â”‚   â””â”€ Span: HTTP POST /v1/chat/completions
  â”œâ”€ Span: Advisor.afterCall (MessageChatMemoryAdvisor)
  â””â”€ Span: Advisor.afterCall (QuestionAnswerAdvisor)
```

### Custom Observations

Add custom metrics and traces:

```java
@Component
public class CustomObservationAdvisor implements RequestResponseAdvisor {
    
    private final ObservationRegistry observationRegistry;
    private final MeterRegistry meterRegistry;
    
    @Override
    public ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context) {
        
        // Record custom metric
        Usage usage = response.getMetadata().getUsage();
        
        meterRegistry.counter(
                "custom.ai.tokens.cost",
                "model", response.getMetadata().getModel()
        ).increment(calculateCost(usage));
        
        // Record finish reason distribution
        String finishReason = response.getResult()
                .getMetadata()
                .getFinishReason();
        
        meterRegistry.counter(
                "custom.ai.finish.reason",
                "reason", finishReason
        ).increment();
        
        return response;
    }
    
    private double calculateCost(Usage usage) {
        // Calculate based on your pricing
        return (usage.getPromptTokens() * 0.005 / 1000.0) +
               (usage.getGenerationTokens() * 0.015 / 1000.0);
    }
}
```

### Logging

Structured logging with SLF4J:

```java
@Component
public class LoggingAdvisor implements RequestResponseAdvisor {
    
    private static final Logger log = LoggerFactory.getLogger(LoggingAdvisor.class);
    
    @Override
    public AdvisedRequest adviseRequest(
            AdvisedRequest request,
            Map<String, Object> context) {
        
        if (log.isDebugEnabled()) {
            log.debug("AI Request - Messages: {}",
                    request.prompt().getInstructions().size());
            
            request.prompt().getInstructions().forEach(msg ->
                    log.debug("  {} - {}", 
                            msg.getMessageType(),
                            truncate(msg.getContent(), 100))
            );
        }
        
        context.put("request_time", Instant.now());
        return request;
    }
    
    @Override
    public ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context) {
        
        Instant requestTime = (Instant) context.get("request_time");
        Duration duration = Duration.between(requestTime, Instant.now());
        
        Usage usage = response.getMetadata().getUsage();
        
        log.info("AI Response - Model: {}, Duration: {}ms, Tokens: {} prompt + {} completion = {}",
                response.getMetadata().getModel(),
                duration.toMillis(),
                usage.getPromptTokens(),
                usage.getGenerationTokens(),
                usage.getTotalTokens());
        
        if (log.isDebugEnabled()) {
            log.debug("Response content: {}",
                    truncate(response.getResult().getOutput().getContent(), 200));
        }
        
        return response;
    }
    
    private String truncate(String str, int maxLength) {
        return str.length() > maxLength 
                ? str.substring(0, maxLength) + "..." 
                : str;
    }
}
```

---

## Extensibility Points

Spring AI is designed for extensibility. Here are the main extension points:

### 1. Custom ChatModel

Implement your own AI provider:

```java
public class CustomAiChatModel implements ChatModel {
    
    private final CustomAiApi api;
    private final ChatOptions defaultOptions;
    
    @Override
    public ChatResponse call(Prompt prompt) {
        // 1. Convert to provider format
        CustomAiRequest request = toCustomAiRequest(prompt);
        
        // 2. Call API
        CustomAiResponse response = api.chat(request);
        
        // 3. Convert to Spring AI format
        return toChatResponse(response);
    }
    
    @Override
    public Flux<ChatResponse> stream(Prompt prompt) {
        // Implement streaming if supported
        return api.chatStream(toCustomAiRequest(prompt))
                .map(this::toChatResponse);
    }
    
    private CustomAiRequest toCustomAiRequest(Prompt prompt) {
        // Map Spring AI Prompt to your API format
        return CustomAiRequest.builder()
                .messages(toApiMessages(prompt.getInstructions()))
                .temperature(getTemperature(prompt))
                .build();
    }
    
    private ChatResponse toChatResponse(CustomAiResponse response) {
        // Map your API response to Spring AI ChatResponse
        AssistantMessage message = new AssistantMessage(response.getText());
        Generation generation = new Generation(message);
        
        ChatResponseMetadata metadata = ChatResponseMetadata.builder()
                .withUsage(new DefaultUsage(
                        response.getInputTokens(),
                        response.getOutputTokens()
                ))
                .withModel(response.getModel())
                .build();
        
        return new ChatResponse(List.of(generation), metadata);
    }
}
```

### 2. Custom VectorStore

Integrate a new vector database:

```java
public class CustomVectorStore implements VectorStore {
    
    private final CustomVectorDb db;
    private final EmbeddingModel embeddingModel;
    
    @Override
    public void add(List<Document> documents) {
        // 1. Generate embeddings
        List<float[]> embeddings = embeddingModel.embed(
                documents.stream()
                        .map(Document::getContent)
                        .toList()
        );
        
        // 2. Store in database
        for (int i = 0; i < documents.size(); i++) {
            Document doc = documents.get(i);
            float[] embedding = embeddings.get(i);
            
            db.insert(
                    doc.getId(),
                    doc.getContent(),
                    embedding,
                    doc.getMetadata()
            );
        }
    }
    
    @Override
    public List<Document> similaritySearch(SearchRequest request) {
        // 1. Embed query
        float[] queryEmbedding = embeddingModel.embed(request.getQuery());
        
        // 2. Search database
        List<CustomVectorDb.SearchResult> results = db.search(
                queryEmbedding,
                request.getTopK(),
                request.getSimilarityThreshold()
        );
        
        // 3. Convert to Documents
        return results.stream()
                .map(result -> {
                    Document doc = new Document(
                            result.getId(),
                            result.getContent(),
                            result.getMetadata()
                    );
                    doc.setScore(result.getScore());
                    return doc;
                })
                .toList();
    }
    
    @Override
    public Optional<Boolean> delete(List<String> idList) {
        idList.forEach(db::delete);
        return Optional.of(true);
    }
}
```

### 3. Custom DocumentReader

Support new file formats:

```java
public class MarkdownDocumentReader implements DocumentReader {
    
    private final Resource resource;
    
    public MarkdownDocumentReader(Resource resource) {
        this.resource = resource;
    }
    
    @Override
    public List<Document> get() {
        try (InputStream is = resource.getInputStream()) {
            String content = new String(is.readAllBytes(), StandardCharsets.UTF_8);
            
            // Parse markdown (using commonmark or flexmark)
            Parser parser = Parser.builder().build();
            Node document = parser.parse(content);
            
            // Convert to plain text
            HtmlRenderer renderer = HtmlRenderer.builder().build();
            String html = renderer.render(document);
            String plainText = Jsoup.parse(html).text();
            
            // Extract metadata from front matter
            Map<String, Object> metadata = extractFrontMatter(content);
            metadata.put("source", resource.getFilename());
            metadata.put("type", "markdown");
            
            return List.of(new Document(plainText, metadata));
            
        } catch (IOException e) {
            throw new RuntimeException("Failed to read markdown", e);
        }
    }
    
    private Map<String, Object> extractFrontMatter(String content) {
        // Extract YAML front matter if present
        if (content.startsWith("---\n")) {
            int endIndex = content.indexOf("\n---\n", 4);
            if (endIndex != -1) {
                String yaml = content.substring(4, endIndex);
                // Parse YAML and return as map
                return parseYaml(yaml);
            }
        }
        return new HashMap<>();
    }
}
```

### 4. Custom Advisor

Add any cross-cutting concern:

```java
/**
 * Caching advisor - cache responses to avoid duplicate API calls.
 */
@Component
public class CachingAdvisor implements RequestResponseAdvisor {
    
    private final Cache<String, ChatResponse> cache;
    
    public CachingAdvisor() {
        this.cache = CacheBuilder.newBuilder()
                .maximumSize(1000)
                .expireAfterWrite(Duration.ofHours(1))
                .build();
    }
    
    @Override
    public AdvisedRequest adviseRequest(
            AdvisedRequest request,
            Map<String, Object> context) {
        
        String cacheKey = generateCacheKey(request);
        ChatResponse cached = cache.getIfPresent(cacheKey);
        
        if (cached != null) {
            context.put("cached_response", cached);
            context.put("cache_hit", true);
        }
        
        context.put("cache_key", cacheKey);
        return request;
    }
    
    @Override
    public ChatResponse adviseResponse(
            AdvisedRequest request,
            ChatResponse response,
            Map<String, Object> context) {
        
        // If we had a cache hit, return cached response
        if (context.containsKey("cached_response")) {
            return (ChatResponse) context.get("cached_response");
        }
        
        // Otherwise, cache the new response
        String cacheKey = (String) context.get("cache_key");
        cache.put(cacheKey, response);
        
        return response;
    }
    
    private String generateCacheKey(AdvisedRequest request) {
        // Hash prompt messages
        return DigestUtils.md5DigestAsHex(
                request.prompt().getInstructions().toString().getBytes()
        );
    }
}
```

---

## Spring AI Design Principles

Understanding the design principles helps you work with Spring AI effectively:

### 1. Convention Over Configuration

Spring AI favors sensible defaults:

```java
// Minimal configuration
ChatClient client = ChatClient.builder(chatModel).build();

// Uses default:
// - System message: none
// - Temperature: 0.7
// - Max tokens: provider default
// - Advisors: none
```

Override only what you need:

```java
ChatClient client = ChatClient.builder(chatModel)
        .defaultSystem("You are helpful")  // Only override this
        .build();
```

### 2. Interface Segregation

Clients depend on minimal interfaces:

```java
// Don't depend on concrete implementation
public class MyService {
    private final OpenAiChatModel openAi;  // âŒ Too specific
}

// Depend on abstraction
public class MyService {
    private final ChatModel chatModel;  // âœ… Portable
}
```

### 3. Dependency Injection Everywhere

Every component is a Spring bean:

```java
@Service
public class MyService {
    // Spring injects these
    private final ChatModel chatModel;
    private final EmbeddingModel embeddingModel;
    private final VectorStore vectorStore;
    private final ChatMemory chatMemory;
    
    // Easy to test - mock any dependency
}
```

### 4. Fail-Fast Validation

Spring AI validates early:

```java
ChatClient.builder(chatModel)
        .defaultAdvisors(null)  // Throws IllegalArgumentException immediately
        .build();

chatClient.prompt()
        .user(null)  // Throws immediately, not during API call
        .call();
```

### 5. Immutability Where Possible

Value objects are immutable:

```java
// Immutable
Prompt prompt = new Prompt("Hello");
prompt.getInstructions().add(new UserMessage("test"));  // UnsupportedOperationException

// ChatResponse is immutable
ChatResponse response = ...;
response.getResults().clear();  // UnsupportedOperationException
```

### 6. Composition Over Inheritance

Use composition for flexibility:

```java
// Not this:
class MyChatModel extends OpenAiChatModel { ... }

// This:
class MyService {
    private final ChatModel chatModel;
    private final RequestResponseAdvisor myAdvisor;
}
```

### 7. Progressive Disclosure

Simple things are simple, complex things are possible:

```java
// Simple: one line
String response = chatClient.prompt("Hello").call().content();

// Complex: full control
ChatResponse response = chatClient.prompt()
        .system("...")
        .user("...")
        .options(options)
        .advisors(advisor1, advisor2)
        .functions("func1", "func2")
        .call()
        .chatResponse();
```

---

## Performance Considerations

Optimize Spring AI applications for production:

### 1. Connection Pooling

Configure HTTP client connection pooling:

```java
@Bean
public RestClient.Builder restClientBuilder() {
    HttpClient httpClient = HttpClient.create()
            .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000)
            .responseTimeout(Duration.ofSeconds(30))
            .doOnConnected(conn ->
                    conn.addHandlerLast(new ReadTimeoutHandler(30))
                            .addHandlerLast(new WriteTimeoutHandler(30)));
    
    return RestClient.builder()
            .requestFactory(new ReactorClientHttpRequestFactory(httpClient));
}
```

### 2. Async Processing

Use reactive programming for non-blocking:

```java
@Service
public class AsyncChatService {
    
    private final ChatClient chatClient;
    
    /**
     * Process multiple questions concurrently.
     */
    public Flux<AnswerPair> answerMultiple(List<String> questions) {
        return Flux.fromIterable(questions)
                .flatMap(question ->
                        Mono.fromCallable(() ->
                                chatClient.prompt(question).call().content()
                        )
                        .subscribeOn(Schedulers.boundedElastic())
                        .map(answer -> new AnswerPair(question, answer))
                );
    }
}
```

### 3. Caching

Cache responses aggressively:

```java
@Configuration
@EnableCaching
public class CacheConfig {
    
    @Bean
    public CacheManager cacheManager() {
        return new CaffeineCacheManager("ai-responses");
    }
}

@Service
public class CachedChatService {
    
    private final ChatClient chatClient;
    
    @Cacheable(value = "ai-responses", key = "#question")
    public String chat(String question) {
        return chatClient.prompt(question).call().content();
    }
}
```

### 4. Batch Processing

Batch embedding generation:

```java
// Inefficient: one at a time
for (String text : texts) {
    float[] embedding = embeddingModel.embed(text);
    // ...
}

// Efficient: batch
List<float[]> embeddings = embeddingModel.embed(texts);
```

### 5. Token Management

Monitor and limit token usage:

```java
@Component
public class TokenLimitAdvisor implements RequestResponseAdvisor {
    
    private static final int MAX_TOKENS_PER_REQUEST = 4000;
    
    @Override
    public AdvisedRequest adviseRequest(
            AdvisedRequest request,
            Map<String, Object> context) {
        
        // Estimate tokens (rough approximation: 1 token â‰ˆ 4 characters)
        int estimatedTokens = request.prompt().getInstructions().stream()
                .mapToInt(msg -> msg.getContent().length() / 4)
                .sum();
        
        if (estimatedTokens > MAX_TOKENS_PER_REQUEST) {
            throw new IllegalArgumentException(
                    "Request too large: " + estimatedTokens + " tokens"
            );
        }
        
        return request;
    }
}
```

### 6. Streaming for Large Responses

Use streaming for better perceived performance:

```java
// Blocking: user waits 10 seconds for full response
String response = chatClient.prompt("Write a long essay").call().content();
// User sees nothing... nothing... nothing... [full text]

// Streaming: user sees progressive updates
chatClient.prompt("Write a long essay")
        .stream()
        .content()
        .subscribe(chunk -> updateUI(chunk));
// User sees: "The" ... "The history" ... "The history of" ... [continues]
```

### 7. Monitoring and Alerting

Set up alerts for:

```yaml
# Prometheus alerts
groups:
  - name: spring-ai
    rules:
      - alert: HighErrorRate
        expr: rate(spring_ai_chat_client_errors_total[5m]) > 0.1
        annotations:
          summary: "High AI error rate"
      
      - alert: HighLatency
        expr: histogram_quantile(0.95, spring_ai_chat_client_request_duration_seconds) > 5
        annotations:
          summary: "AI requests are slow"
      
      - alert: TokenBudgetExceeded
        expr: increase(spring_ai_chat_client_tokens_total[1d]) > 1000000
        annotations:
          summary: "Daily token budget exceeded"
```

---

## Advanced Architecture Patterns

Production-ready patterns for Spring AI:

### 1. Multi-Model Strategy

Use different models for different tasks:

```java
@Configuration
public class MultiModelConfig {
    
    @Bean
    @Qualifier("fast")
    public ChatClient fastChatClient(
            @Qualifier("openAiChatModel") ChatModel gpt35) {
        return ChatClient.builder(gpt35)
                .defaultOptions(ChatOptions.builder()
                        .withModel("gpt-3.5-turbo")
                        .withMaxTokens(500)
                        .build())
                .build();
    }
    
    @Bean
    @Qualifier("smart")
    public ChatClient smartChatClient(
            @Qualifier("openAiChatModel") ChatModel gpt4) {
        return ChatClient.builder(gpt4)
                .defaultOptions(ChatOptions.builder()
                        .withModel("gpt-4o")
                        .withMaxTokens(2000)
                        .build())
                .build();
    }
    
    @Bean
    @Qualifier("creative")
    public ChatClient creativeChatClient(
            @Qualifier("anthropicChatModel") ChatModel claude) {
        return ChatClient.builder(claude)
                .defaultOptions(ChatOptions.builder()
                        .withTemperature(1.0)
                        .build())
                .build();
    }
}

@Service
public class SmartRoutingService {
    
    @Qualifier("fast")
    private final ChatClient fastClient;
    
    @Qualifier("smart")
    private final ChatClient smartClient;
    
    @Qualifier("creative")
    private final ChatClient creativeClient;
    
    public String chat(String message, TaskType type) {
        return switch (type) {
            case SIMPLE_QA -> fastClient.prompt(message).call().content();
            case COMPLEX_REASONING -> smartClient.prompt(message).call().content();
            case CREATIVE_WRITING -> creativeClient.prompt(message).call().content();
        };
    }
    
    enum TaskType { SIMPLE_QA, COMPLEX_REASONING, CREATIVE_WRITING }
}
```

### 2. Hierarchical RAG

Multi-level retrieval for better accuracy:

```java
@Service
public class HierarchicalRagService {
    
    private final VectorStore chunkStore;      // Fine-grained chunks
    private final VectorStore documentStore;   // Document summaries
    private final ChatClient chatClient;
    
    public String answerWithHierarchicalRag(String question) {
        
        // Level 1: Find relevant documents by summary
        List<Document> relevantDocs = documentStore.similaritySearch(
                SearchRequest.query(question).withTopK(5)
        );
        
        // Level 2: For each relevant document, find specific chunks
        List<Document> relevantChunks = relevantDocs.stream()
                .flatMap(doc -> {
                    String docId = doc.getId();
                    
                    // Search chunks belonging to this document
                    FilterExpression filter = new Filter.Expression(
                            Filter.ExpressionType.EQ,
                            new Filter.Key("document_id"),
                            new Filter.Value(docId)
                    );
                    
                    return chunkStore.similaritySearch(
                            SearchRequest.query(question)
                                    .withTopK(3)
                                    .withFilterExpression(filter)
                    ).stream();
                })
                .limit(10)  // Top 10 chunks overall
                .toList();
        
        // Build context
        String context = relevantChunks.stream()
                .map(Document::getContent)
                .collect(Collectors.joining("\n\n"));
        
        // Generate answer
        return chatClient.prompt()
                .system("""
                        Answer based on the following context.
                        If unsure, say "I don't know."
                        """)
                .user("Context: " + context + "\n\nQuestion: " + question)
                .call()
                .content();
    }
}
```

### 3. Agent Pattern

Autonomous agents that plan and execute:

```java
@Service
public class AgentService {
    
    private final ChatClient chatClient;
    private final Map<String, FunctionCallback> tools;
    
    public String executeTask(String task) {
        String systemPrompt = """
                You are an autonomous agent. You can use tools to complete tasks.
                
                Available tools:
                - search: Search the web
                - calculate: Perform calculations
                - sendEmail: Send emails
                
                Think step-by-step:
                1. Understand the task
                2. Plan which tools to use
                3. Execute tools in sequence
                4. Synthesize results
                """;
        
        // Agentic loop
        String currentThought = task;
        int maxIterations = 5;
        
        for (int i = 0; i < maxIterations; i++) {
            
            ChatResponse response = chatClient.prompt()
                    .system(systemPrompt)
                    .user(currentThought)
                    .functions(tools.keySet().toArray(String[]::new))
                    .call()
                    .chatResponse();
            
            String content = response.getResult().getOutput().getContent();
            
            // Check if task complete
            if (content.contains("[TASK_COMPLETE]")) {
                return content.replace("[TASK_COMPLETE]", "").trim();
            }
            
            // Continue with next thought
            currentThought = content;
        }
        
        return "Task could not be completed within iteration limit.";
    }
}
```

### 4. Ensemble Pattern

Combine multiple models for better results:

```java
@Service
public class EnsembleService {
    
    private final List<ChatClient> models;
    
    public String ensembleChat(String question) {
        
        // Get responses from all models
        List<String> responses = models.stream()
                .map(client -> client.prompt(question).call().content())
                .toList();
        
        // Use a judge model to select best response
        ChatClient judgeModel = models.get(0);  // Use first as judge
        
        String judgePrompt = """
                Multiple AI models answered the same question.
                Select the best, most accurate answer.
                
                Question: %s
                
                Answers:
                %s
                
                Return only the number (1-%d) of the best answer.
                """.formatted(
                        question,
                        IntStream.range(0, responses.size())
                                .mapToObj(i -> (i + 1) + ". " + responses.get(i))
                                .collect(Collectors.joining("\n\n")),
                        responses.size()
                );
        
        String judgement = judgeModel.prompt(judgePrompt).call().content();
        int bestIndex = Integer.parseInt(judgement.trim()) - 1;
        
        return responses.get(bestIndex);
    }
}
```

---

## Migration and Upgrade Strategies

### Migrating from LangChain4j

If you're coming from LangChain4j:

**LangChain4j**:
```java
ChatLanguageModel model = OpenAiChatModel.builder()
        .apiKey(System.getenv("OPENAI_API_KEY"))
        .modelName("gpt-4")
        .build();

String response = model.generate("Hello");
```

**Spring AI**:
```java
@Autowired
ChatClient chatClient;

String response = chatClient.prompt("Hello").call().content();
```

**Key differences**:
- Spring AI uses Spring Boot auto-configuration (no manual building)
- `ChatClient` is the primary API (simpler than direct model usage)
- Advisors replace LangChain4j's memory/RAG implementations

### Upgrading Spring AI Versions

**0.8.x â†’ 1.0.0 Breaking Changes**:

1. **ChatClient API introduced** (replacing direct ChatModel usage)
2. **Advisor API changed** (new `RequestResponseAdvisor` interface)
3. **VectorStore interface simplified**

**Migration steps**:

```java
// Old (0.8.x)
ChatModel chatModel = ...;
String response = chatModel.call(new Prompt("Hello"))
        .getResult()
        .getOutput()
        .getContent();

// New (1.0.0+)
ChatClient chatClient = ChatClient.builder(chatModel).build();
String response = chatClient.prompt("Hello").call().content();
```

---

## Conclusion

We've covered Spring AI's architecture from bottom to top:

**Core Abstractions**: `ChatModel`, `EmbeddingModel`, `VectorStore` interfaces provide portability across AI providers. Your code depends on abstractions, not implementations.

**ChatClient**: The fluent API that makes AI interactions feel natural and Spring-like. Build requests declaratively, execute synchronously or reactively.

**Advisors**: The AOP of AIâ€”add cross-cutting concerns (memory, RAG, logging, metrics) without cluttering business logic. Composable, reusable, testable.

**Auto-Configuration**: Spring Boot magic that wires everything together. Add a dependency, set properties, and you have a working AI application.

**Streaming & Reactive**: Project Reactor integration for non-blocking, high-throughput applications. Stream responses to users for better UX.

**Function Calling**: Let AI models invoke your Java methods. Build agentic applications where AI orchestrates complex workflows.

**Structured Outputs**: Extract typed Java objects from unstructured AI responses. Type-safe, validated data extraction.

**Vector Stores**: The foundation of RAG architectures. Store, search, and retrieve documents by semantic similarity.

**Observability**: Built-in metrics, tracing, and logging. Production-ready monitoring out of the box.

**Extensibility**: Well-defined extension points for custom models, stores, readers, and advisors. Build on Spring AI's foundation.

### Key Takeaways

**Spring AI's design philosophy**:
- **Abstraction for portability**: Switch providers without code changes
- **Convention over configuration**: Sensible defaults, override only what you need
- **Composition over inheritance**: Flexible, testable architectures
- **Progressive disclosure**: Simple things simple, complex things possible

**When to use Spring AI**:
- âœ… Building Spring Boot applications with AI capabilities
- âœ… Need to support multiple AI providers
- âœ… Want production-ready observability and resilience
- âœ… Prefer declarative, Spring-style APIs
- âœ… Building RAG (Retrieval-Augmented Generation) applications

**When to consider alternatives**:
- âš ï¸ Non-Spring Java applications (consider LangChain4j)
- âš ï¸ Need cutting-edge features from a single provider (use provider SDK directly)
- âš ï¸ Python-based projects (use LangChain)

### What's Next?

Now that you understand Spring AI's architecture, you can:

1. **Build RAG applications** with confidence, understanding how vector stores, embeddings, and advisors work together
2. **Create custom integrations** by implementing `ChatModel`, `VectorStore`, or `DocumentReader`
3. **Optimize performance** by leveraging caching, batching, and streaming
4. **Debug production issues** by understanding request flow through advisors and models
5. **Contribute to Spring AI** with knowledge of its design patterns and principles

### Further Resources

**Official Documentation**:
- [Spring AI Reference](https://docs.spring.io/spring-ai/reference/)
- [Spring AI GitHub](https://github.com/spring-projects/spring-ai)
- [Spring AI Samples](https://github.com/spring-projects/spring-ai-examples)

**Community**:
- [Spring AI on Discord](https://discord.gg/spring)
- [Stack Overflow: spring-ai tag](https://stackoverflow.com/questions/tagged/spring-ai)

**Advanced Topics** (for future deep dives):
- Building multi-agent systems with Spring AI
- Production deployment patterns and scaling strategies
- Cost optimization techniques
- Security and compliance (PII handling, content filtering)
- Hybrid search architectures (combining keyword and vector search)

---

**Thank you for reading this complete guide to Spring AI architecture!**

Understanding the architecture empowers you to build better AI applications. You now know not just *how* to use Spring AI, but *why* it works the way it does.

If you found this guide helpful, please:
- â­ Star the [Spring AI GitHub repository](https://github.com/spring-projects/spring-ai)
- ğŸ¦ Share on Twitter/X
- ğŸ’¬ Join the Spring AI community discussions
- ğŸ¤ Contribute backâ€”Spring AI is open source!

**Questions or feedback?** Reach out to the SpringDevPro team or join the Spring AI Discord.

Happy coding with Spring AI! ğŸš€

---

*Last updated: November 20, 2025*  
*Author: SpringDevPro Team*  
*License: CC BY 4.0*